{"pages":[],"posts":[{"title":"Hello World","text":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new \"My New Post\" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment","link":"/2018/11/25/hello-world/"},{"title":"博客更新为 Hexo 静态博客 + 语雀","text":"缘起之前博客使用的是 TeenyBlog 2.0 的方案，现在，因为有了 yuque-hexo 这个玩意，我可以把语雀上面的文章同步到 Hexo 了，同步到静态博客是我最开始的想法。TeenyBlog 是过渡期间的一个解决方案。现在他可能要被废弃了。 经过首先，我还是得说，语雀是个好东西，markdown 我真的不太喜欢写，太不伦不类了。 TennyBlog 一直困扰我的问题，是语雀用的 SPA 加载太慢，搜索引擎也没法收录。恰巧，我遇见了 yuque-hexo 这个玩意，可以无缝同步文章到 Hexo ，于是我果断转移了战线。 我之前并没有接触过 Hexo ，找模板花了一些时间，最终选了 AirCloud ，然后一番魔改，加入了没有人用的 评论系统 。 yuque-hexo 也有一些问题，改 bug 啥的花了1天时间。 最后是考察放哪里的问题，Github Pages 速度太慢也不稳定，不予考虑。Coding.net 要放友链，也暂时不考虑。 一个备选方案是 腾讯 COS + 免备案CDN ，但是实测速度不理想，如果是已经备案的同学推荐这个方案，改用腾讯云自家 CDN就非常快。另外 Hexo 有 COS 的部署插件。不推荐 OSS，因为子文件夹不能使用 index.html 作为默认页。 最后我只好放在我的香港腾讯云上面，折腾了一下 nginx ，上了 HTTP/2，TLS 1.3 ，速度也勉强过得去。 结语生命在于折腾，也欢迎使用了我的 TeenyBlog 2.0 方案的童鞋转回正常的静态博客。 yuque-hexo 理论上也可以无缝支持其他类似的静态博客产品（魔改一下即可）","link":"/2018/10/02/yuque/hexo-yuque/"},{"title":"Java 动态代理机制 （一） JDK Proxy详解","text":"JDK Proxy 代理是可以根据我们的 接口 Interface 生成类的字节码，从而可以在 Java 中为所欲为的一种技术，包括对象增强（修改成员变量），函数增强（在函数前后执行别的代码），根据接口名执行不同逻辑 等。在 Mybatis 中有典型应用。它的本质是 由 Proxy 生成一个 代理对象，实现我们的接口。这个对象中有我们的回调函数。当调用 代理对象的接口方法时，这个对象再调用我们的回调函数，我们的回调函数再调用原对象的对应方法。从而实现代理。为了实现代理模式，Proxy 用了另外一种设计模式：命令模式。 不过，如果我们没有接口，直接是个类，那么 Proxy 将不能用，我们可能需要用 CGLIB 等 ASM 框架进行对类的字节码进行修改。 用法简介定义一个接口和一个实现的对象 123456789101112// 规定一个接口public interface IHello { void sayHello();}// 新建一个对象IHello hello = new Hello(){ @Override public void sayHello() { System.out.println(\"Hello!\"); }}; 不增强时，我们平时调用的话是这样：1234hello.sayHello()// 输出：// Hello! 使用反射调用，可以达到同样的效果：1234// 从类的字节码获取到方法Method method = hello.getClass().getMethod(\"sayHello\");// 指定一个对象执行method.invoke(hello); 我们使用 JDK 的 Proxy 对对象进行增强： 1234567891011121314151617181920// 对这个对象进行增强，三个参数IHello iHello = (IHello) Proxy.newProxyInstance( IHello.class.getClassLoader(), // 类加载器 new Class[]{IHello.class}, // 所有接口 new InvocationHandler() { // 回调函数 handler 打包成对象，可以用 lambda @Override public Object invoke(Object proxy, Method method, Object[] args) throws Throwable { System.out.println(\"前置通知\"); Object rs = method.invoke(hello, args); // 这里指定由我们的 hello 对象执行 System.out.println(\"后置通知\"); return rs; } });// 调用iHello.sayHello();// 输出：// 前置通知// Hello!// 后置通知 我们看到，我们给 Proxy.newProxyInstance 传入了一个类加载器、一个接口的数组、一个 Handler。返回的是一个 动态生成的 Proxy 对象，实现了 IHello 接口 我们在调用 这个Proxy 对象的 sayHello() 的时候，实际上调用的是我们 handler 的 invoke 方法，然后将我们的 method（类比上面的 hello.getClass().getMethod(“sayHello”)） 传入，然后我们在 invoke 方法里面已经指定了由原来的对象执行这个方法，method.invoke(hello, args)，所以整个代理就完成了。 用法解析方法增强/对象增强Proxy 本质上是根据我们的接口生成了一个 Proxy 对象，然后这个对象再调用我们指定的逻辑来实现动态代理的。而在我们的逻辑中，要用 反射的方法 回调真正对象的方法来实现对象增强。在反射调用的前后，我们还执行别的一些额外的逻辑。为什么要这么增强呢？这其实是一种AOP的编程方法。 在 SpringMVC 的一些逻辑操作中，我们可以用到它，比如每个方法统一鉴权，日志处理等等，我们可以在一个地方写一次代码，就可以应用到全部方法中。当然 Proxy 还不灵活，默认会对接口的所有方法都执行同一个逻辑，所以我们还有 AspectJ 等包来灵活管理。 根据接口名执行不同方法当然，我们也可以不做对象增强，而是直接读取我们的接口中的方法名，做一些别的逻辑，比如 在 Mybatis 中，我们只要定义接口，然后经过工厂返回一个 Proxy 对象，我们就可以调用到真正的逻辑代码，读取 map 和 数据库。 原理解析眼见为实，我们来把经过代理后的对象的类文件导出来，再确认下我们的结论： 1234567try(FileOutputStream fos = new FileOutputStream(path)) { fos.write(classFile); fos.flush(); System.out.println(\"代理类class文件写入成功\");} catch (Exception e) { System.out.println(\"写文件错误\");} 为了简洁起见，这里删掉了对 Object代理 的 一些方法 1234567891011121314151617181920212223242526272829303132333435363738public final class $Proxy0 extends Proxy implements IHello { // 实现原接口，是代理模式的核心 private static Method m3; static { try { m3 = Class.forName(\"test.ProxyTest$IHello\").getMethod(\"sayHello\"); // 调用了 getMethod 方法 } catch (NoSuchMethodException var2) { throw new NoSuchMethodError(var2.getMessage()); } catch (ClassNotFoundException var3) { throw new NoClassDefFoundError(var3.getMessage()); } } public $Proxy0(InvocationHandler var1) throws { super(var1); // 把我们的 Handler 传进来了 } // super(var1) 方法的代码，非本文件 protected Proxy(InvocationHandler h) { Objects.requireNonNull(h); this.h = h; } public final void sayHello() throws { try { // 这里回调我们传入的 handler 类 super.h.invoke(this, m3, (Object[])null); // 因为我们的接口没有参数，所以这里传null } catch (RuntimeException | Error var2) { throw var2; } catch (Throwable var3) { throw new UndeclaredThrowableException(var3); } } // super.h.invoke 方法就是我们自己定义的 Handler 的 invoke 方法 // 如果有其他方法，就直接由生成器复制即可} 这其实是命令模式的设计模式，我们先传入一个回调函数，Proxy 被调用时，调用我们的的回调函数（对象） 参考资料https://www.cnblogs.com/gonjan-blog/p/6685611.html","link":"/2018/07/17/yuque/jdk-proxy/"},{"title":"今日诗词 API - 诗词实时智能推荐","text":"简介今日诗词 API 是一个可以返回一句古诗词名句的接口。它可以通过图片和 JSON 格式调用。今日诗词 API 根据不同地点、时间、节日、季节、天气、景观、城市、事件进行智能推荐。 演示： 官网： https://www.jinrishici.com/ 调用文档： https://www.jinrishici.com/doc/ 怎么调用博客类的网站可以直接使用 sdk 调用 引入：1&lt;script src=\"https://sdk.jinrishici.com/v2/browser/jinrishici.js\" charset=\"utf-8\"&gt;&lt;/script&gt; 在需要添加的地方加一个 id=&quot;jinrishici-sentence&quot; 比如：1&lt;span id=\"jinrishici-sentence\"&gt;正在加载今日诗词....&lt;/span&gt; 另有回调函数，可以自行处理，详见 文档 论坛文章可以调用图片 1https://v2.jinrishici.com/one.svg 另有小程序 SDK，详见 文档 为什么要做这个接口在一些游戏中，根据游戏内不同的天气或日期，可以触发一系列“奇遇”或者“成就”，这个感觉非常过瘾。我的想法也是想打通虚拟与现实的界限，做一个没有人做过的诗词推荐产品。当然也感谢一些网友（见 文档 致谢）的建议。 推荐怎么做的在推荐方面，主要是能根据真实世界的环境做出诗词推荐。这个和传统的推荐系统不同，并不是基于历史数据集推荐的的形式，而主要是利用时间地点上下文信息，把时间地点天气信息转化为事件，根据事件标签进行相关推荐。这个领域我目前还没有看到有相关的产品，所以也是摸石头过河的状态。在评估诗词好坏，推荐契合度的时候，也引入了一些指标，但是具体效果仍待评估。 当然这也可能是一个恶性循环，因为我们没有办法收集用户的喜好，所以可能永远没有办法做到根据个人喜好推荐。当然，也有考虑商用版本，可以基于注册用户的推荐。 这个产品只有我一个人完成，所以无论是推荐事件制定还是诗词源标注上，都是以我自己的经验制定和打标，难免有偏颇之处，不过广大 v 友也可以提提意见，看看如何不断改进这个系统。十分感谢。 详细的推荐思路和推荐标签： https://www.jinrishici.com/doc/#how 关于产品为了方便广大赖人站长朋友添加这个 API 到网站上，我在上一个版本就已经“独家”搞出基于 svg 的接口返回的形式，不过具体使用上可能还是稍微麻烦。现在我直接把 SDK 也写好，就可以像百度统计一样直接复制调用了。 我也想把影响力扩展到小程序上面，我们为小程序也提供了 SDK，并且我重新注册了一个 .com 域名并且备案（旧接口仍然提供服务，域名不变）。 关于开发上一个版本接口用的是 vert.x 开发，vert.x 引入了大量 js 风格，在中大型项目上面非常蛋疼，比如没有 POJO，全是 JsonObject。没有接口，只有类似反射的调用方法。没有 IOC，只能自己 new。还有可怕的回调地狱。 好在 Spring 给了 Java 异步开发者一些希望。Spring Webflux 经过一年多的迭代，已经达到基本能用的水平。尤其是配套的 Reactor 3 采用了类似 Rxjava 的链式操作（或者可以理解为 Stream 的异步加强版），大幅简化了并行开发，异步开发的难度，提高了可读性。目前 Spring Webflux 已经集成在 Spring Boot 2 中，无缝和 SpringMVC 使用方法对接，并且可以无缝享受到 Spring Boot 全家桶。本接口采用 Webflux 开发。 然而 Webflux 也继承了 Spring 家一贯臃肿的风格，性能比 Vert.x 差不少，不过好歹也是运行在 Netty 上，比同步开发的响应速度还是有质的提高。 写在后面更多有关本产品的细节，我已经在 文档 中阐述。当然，在使用之前，你需要同意我们的使用协议。（不能使用在违法网站上等）。","link":"/2018/10/02/yuque/jinrishici/"},{"title":"SSM开发 - 开发自定义插件，使 mybatis-generator 支持软删除","text":"提要本文是 小小商城-SSM版的 细节详解系列 之一，项目 github：https://github.com/xenv/S-mall-ssm 本文代码大部分在 github 中 可以找到。 我们在开发的过程中，往往会使用到软删除，即删除时不真正删除还是打标记，但是这样在查询的时候往往会遇到一些麻烦，特别是使用 mybatis-generator 的时候，因为不好自定义生成的 mapper ，这样在查询的时候很容易把已经打标的数据又查出来，非常不安全。 那么，我们怎么让 mybatis-generator 生成的 mapper 支持软删除呢，还好，我们可以通过开发自定义插件实现。 具体实现完整实现代码见：DeleteAtPlugin.java 新建插件类，继承PluginAdapter，重写validate(..)方法，让其直接 return true; 不进行参数校验 重写 sqlMapExampleWhereClauseElementGenerated(…)方法，这个是 生成selectByExample 部分的 mapper 代码的钩子，我们在合适的地方（我是debug找的），加入一个软删除标记 is null 即可 重写 sqlMapSelectByPrimaryKeyElementGenerated(…)方法，我们在合适的地方，加入一个软删除标记 is null 即可 完整代码： 1234567891011121314151617181920212223242526272829public class DeleteAtPlugin extends PluginAdapter { @Override public boolean sqlMapExampleWhereClauseElementGenerated(XmlElement element, IntrospectedTable introspectedTable) { for (Element child : element.getElements()) { if (child instanceof XmlElement &amp;&amp; ((XmlElement) child).getName().equals(\"where\")) { TextElement element1 = new TextElement(\"and deleteAt is NULL\"); ((XmlElement) child).getElements().add(element1); break; } } return true; } @Override public boolean sqlMapSelectByPrimaryKeyElementGenerated(XmlElement element, IntrospectedTable introspectedTable) { TextElement element1 = new TextElement(\"and deleteAt is NULL\"); element.getElements().add(element1); return true; } @Override public boolean validate(List&lt;String&gt; list) { return true; }} 配置mybatis-generator插件 123456789&lt;generatorConfiguration&gt; &lt;context id=\"Mysql\" targetRuntime=\"MyBatis3\" &gt; &lt;!--给select增加deleteAt is null属性--&gt; &lt;plugin type=\"tmall.util.MBGPlugins.DeleteAtPlugin\"&gt; &lt;/plugin&gt; .... &lt;/context&gt; ...&lt;/generatorConfiguration&gt; 在Service删除时候，调用 update方法而不是delete方法 ，使软删除标记不为空即可。 OK，大功告成","link":"/2018/05/31/yuque/mybatis-generator-delete-flag/"},{"title":"SSM开发 - 合理配置 mybatis-generator，隔离机器生成代码和额外增加代码","text":"提要 本文是 小小商城-SSM版的 细节详解系列 之一，项目 github：https://github.com/xenv/S-mall-ssm 本文代码大部分在 github 中 可以找到。 在中小型项目I中，我们常常使用 mybatis-generator 直接生成实体类、mapper、example代码。但是，在实际开发中，我们有可能会需要增加实体类的变量（比如一些前台的临时变量和一对多、多对一变量等等），修改mapper代码，如果在机器生成的代码上面直接修改，那么我们下次修改了数据库，想重新生成的时候就会覆盖掉旧的手写代码了。所以必须要想出一种解决办法来隔离生成代码和额外增加代码。 最简单的方法，就是使用 IDE 的插件，但是这种方法没有普适性，可能换一个IDE就傻眼了，或者在实际部署的时候，也不一定有IDE的环境 ，所以这种做法可行，但是不是太好。 一般的方法，就是 另起炉灶，开一个 Extension 类 / VO 类，再继承机器生成的类。如下图。然而，这种方法意味着 mapper 也要 重写，工作量大不说，还很容易出错，也不容易管理，使用 mybatis-generator 的意义也不是太大。 传统方式 在这里，我提出了一种新的解决方案，如下图： 这种方法的巧妙之处在于，Service层调用的就是机器直接生成的代码，而让机器的代码去继承我们自己写的代码，这样，mapper不用额外写，example也可以支持，调用的时候又隐藏了 实体扩展类，干净整洁。 具体实现 具体实现其实非常简单。小小商城的完整配置见 generatorConfig.xml 1. 修改mybatis-generator设置 ，让生成的实体类继承我们手写 Extension mybatis-generator其实支持我们直接去继承指定的类，只要在 table 配置中加入 “rootClass” 一行即可 123456&lt;table tableName=\"category\" domainObjectName=\"Category\" enableCountByExample=\"false\" enableUpdateByExample=\"false\" enableDeleteByExample=\"false\" enableSelectByExample=\"true\" selectByExampleQueryId=\"false\"&gt; &lt;property name=\"rootClass\" value=\"tmall.pojo.extension.CategoryExtension\"/&gt; &lt;property name=\"my.isgen.usekeys\" value=\"true\"/&gt; &lt;property name=\"useActualColumnNames\" value=\"true\"/&gt; &lt;generatedKey column=\"id\" sqlStatement=\"JDBC\"/&gt;&lt;/table&gt; 2. 手动新建 Extension 类，重新生成代码即可","link":"/2018/05/31/yuque/mybatis-generator-insulate/"},{"title":"“哪煮米”域名比价网站开发踩坑记","text":"网站介绍 哪煮米是一个我自己独自操刀的域名比价平台，会显示不同域名后缀，不同注册商的注册价格，支持横向对比和纵向对比。并且支持多种条件筛选，非常人性化。首页：https://www.nazhumi.com 为什么做这个网站 自己有这方面的需求，也在Q群聊天里面知道还有一些朋友也有类似的需求。 国外已经有 domcomp、tld-list 网站，但是对于中国用户来说使用体验不太好，支持的域名商也不全面，尤其是不支持国内的域名注册商。 国内也有一些类似的网站，问题也主要在域名注册商太少。这样就导致一个很严重的问题：价格谈不上实惠。 想系统总结一下自己的技术，做一些创造性的工作搬砖。 开发这个网站有哪些坑 这个网站我尝试了全新的JAVA技术栈（Springboot全家桶），确实方便，但坑也变得很多。 首先说下方便的地方 Spring Data JPA + Hibernate 的组合，确实十分方便，特别是定义完DAO接口之后马上就可以使用（动态代理的一些机制），既解决了原来 Hibernate 各种 前置后置操作，也不用再取出后担心再转类型导致不安全的问题。在 ORM 领域可以说是开辟了一个新天地了。和直接使用 MongoDB 的体验相差无几，还支持复杂的一些关联操作。 Springboot本身配置少，省去了配置找百度的很多时间，也大大提高了可扩展性。比如要加入日志、redis等就变得非常方便，和Maven整合之后，也不用关注各个组件的版本号。 启动更加方便，不用再折腾Tomcat，只要Jar包就可以启动。 再说下比较坑爹的地方 SpringBoot 默认的模板引擎 Thymeleaf 极其不好用。 首先比如文档必须是html，但是又要求各种模板变量必须在 双引号 以内，不能直接在两标签中调用变量，并且不提供转义符号。 组件也不太好用，组件必须包在一个标签中，但是又不提供像 vue 或者 小程序 里面的 block/template 等无意义标签。 不支持 的使用方法，必须还是JSP的老一套。总之，如果你用过 vue 或者 小程序做前端开发的话，再转过来用 Thymeleaf ，就会得到一种酸爽的体验。截取了一小段判断逻辑供大家体验。 2. jar包直接启动仍然不方便，在实际生产环境中，需要根域名跳转到www，Springboot没法提供好的方案，无奈只能用 nginx反代一下。当然这个也是微服务的趋势。另外，如果要增加一些 图标资源 ，改动一下 html，也必须重新打包，有点麻烦。 3. SpringData JPA 中没有提供 像 Hibernate 查询器的一些方便的面向对象的sql生成机制，复杂动态查询的时候使用起来比较繁琐。 还有哪些遗憾 没有做输入一个域名前缀搜索是否可以注册的功能，专注于注册商比价。原因主要是因为没有找到合适的接口。不过，其实很多域名注册商本身也支持数百个后缀，查询域名是否可注册并不麻烦。 未来给自己留了哪些坑 现在访问量较少，如果用户增多，可能会考虑用 Redis 暂存 优化资源占用量。如果用户暴增则可能还需要考虑负载均衡（不可能的）。 还有便宜的许多域名注册商没有收录，主要是各国本地的注册商，对于该国的后缀注册一般会比较便宜。（如 .cn 国内注册只需二十元，但是外国注册商都是十美元起），这个精力有限，日后有时候再慢慢添加。 很有可能不赚钱，必须自己支付相关费用。","link":"/2018/06/20/yuque/nazhumi/"},{"title":"Servlet开发 - 利用 Filter + 反射 处理 URL， 精简 servlet-mapping","text":"提要在原生 Servlet 开发中，如果采用一个 url 对应一个 servlet-mapping，那么web.xml将会十分冗长难以维护。其实，我们其实可以通过 Filter + 反射 来 使 一个 servlet 处理 多个 url ，并且根据不同url调用到 servlet 中的不同方法 （类似SpringMVC） 根据下面的代码实现之后，可以实现 用户访问 /test的时候，就会自动调用 FrontServlet 下面 的 test() 方法，并且根据 该 方法的返回值 来 返回 jsp 文件 或者是 跳转，用户访问 /test2 的时候，就会调用 test2() 方法，以此类推。 本文是 小小商城-Servlet版的 细节详解系列 之一，项目 github：https://github.com/xenv/S-mall-servlet/ 本文代码大部分在 github 中 可以找到 具体实现完整的实现代码见：https://github.com/xenv/S-mall-servlet/blob/master/src/filter/BackServletFilter.java 创建 Filter 文件，implements Filter ，override doFilter 方法 在doFilter 方法中获取 uri 123456//获取根容器目录String contextPath = request.getServletContext().getContextPath();//获取完整 uriString uri = request.getRequestURI();//除根 uri 根目录uri = StringUtils.remove(uri,contextPath); 根据不同的 uri ，获取到对应的 函数 名，插入到request中，比如，我们简单在这里直接把根目录下的 uri 直接 转成 函数 名 123456789if(!(uri.contains(\".\") || (uri.lastIndexOf('/')&gt;0))){ // 根目录 不含.的 uri String method = uri.substring(1); request.setAttribute(\"method\",method); String servletPath = \"front.servlet\"; request.getRequestDispatcher(servletPath).forward(request,response); ...}//其他请求放行filterChain.doFilter(request,response); 根据不同的uri，调用 Servlet，比如，我们简单在这里直接 调用 一个固定的 servlet 12String servletPath = \"front.servlet\";request.getRequestDispatcher(servletPath).forward(request,response); 在Servlet中，重写service方法，我们读取 刚刚传进来的 method ，反射调用相关方法，并把 request 和 responce 传进去 12345678910111213141516@Overrideprotected void service(HttpServletRequest req, HttpServletResponse resp) throws xception { String method = (String)req.getAttribute(\"method\"); //利用反射把url中的方法文本转化为方法进行调用 req.setCharacterEncoding(\"utf-8\"); Method m = this.getClass().getMethod(method,HttpServletRequest.class,HttpServletResponse.class); String redirect = m.invoke(this,req,resp).toString(); if(redirect.startsWith(\"@\")){ resp.sendRedirect(redirect.substring(1)); }else if(redirect.startsWith(\"%\")) resp.getWriter().print(redirect.substring(1)); else req.getRequestDispatcher(redirect).forward(req, resp);} 在这里，我们的method会返回一个String，如果这个String是 @ 开头，那么是跳转，相当于 Springmvc 的 (redirect:) ，如果是 %开头，则是返回纯文本，其他开头则 调用那个 JSP （相当于 Springmvc 的视图定位） 对于非法访问的情况，可能会出错，我们必须要进行错误处理，这里只是简单一个简单演示 在具体method中，我们需要接受 request 和 responce，返回String，例如 12345public String delete(HttpServletRequest request , HttpServletResponse response){ int id = Integer.parseInt(request.getParameter(\"id\")); service.delete(id); return \"@/admin/category_list\";} 在web.xml配置 filter 和 servlet 12345678910111213141516&lt;filter&gt; &lt;filter-name&gt;BackServletFilter&lt;/filter-name&gt; &lt;filter-class&gt;filter.BackServletFilter&lt;/filter-class&gt;&lt;/filter&gt;&lt;filter-mapping&gt; &lt;filter-name&gt;BackServletFilter&lt;/filter-name&gt; &lt;url-pattern&gt;/*&lt;/url-pattern&gt;&lt;/filter-mapping&gt;&lt;servlet&gt; &lt;servlet-name&gt;FrontServlet&lt;/servlet-name&gt; &lt;servlet-class&gt;servlet.FrontServlet&lt;/servlet-class&gt;&lt;/servlet&gt;&lt;servlet-mapping&gt; &lt;servlet-name&gt;FrontServlet&lt;/servlet-name&gt; &lt;url-pattern&gt;/front.servlet&lt;/url-pattern&gt;&lt;/servlet-mapping&gt; 这样，用户访问 /test的时候，就会自动调用 Frontservlet 下面 的 test() 方法，并且根据 该 方法的返回值 来 返回 jsp 文件 或者是 跳转 总结用户访问 url ，先到 Filter ，filter 根据 url ，获取相应的 method 和 servlet ，然后 filter 把控制权交给 servlet， serlvet再根据 method 调用 具体的方法，返回要加载 jsp 文件 或者 跳转，这样我们就实现了和 SpringMVC 大致一样的效果。","link":"/2018/05/31/yuque/servlet-filter-mapping/"},{"title":"小小商城项目概述 —— 需求分析、数据表设计、原型设计、多层结构设计、项目规划","text":"简介小小商城项目是一个 在线商城 的WEB开发项目，主要目的是用来练手和熟悉基本的业务流程，我花了过去四个月时间来完成这个项目。 项目的 github: https://github.com/xenv/S-mall-ssm https://github.com/xenv/S-mall-ssh https://github.com/xenv/S-mall-servlet 欢迎点赞 演示：http://small.ડ.com/ 账号 demo 密码 demo 需求分析前台展示部分：首页、分类页、搜索页、产品页。首页主要显示分类和产品的内容，产品页则还包括详情图片、评论两块内容。鉴于项目较小，没有再实现一个商铺页，而是统一使用分类页。 用户部分：登录、注册，比较简单，还要额外考虑用户组问题用于鉴权。 订单部分：加入购物车/直接购买 -&gt; 下单填写地址 -&gt; 支付 -&gt; 发货 -&gt; 确认收货 -&gt; 评价 -&gt; 我的订单 后台： 网站设置、分类管理 -&gt; 产品管理 -&gt; 产品属性、产品图片 、 用户管理、订单管理 数据表设计难点在于处理 多对多 的关系，要把它转化成 两个 一对多 的关系，并且有一个中间表 具体见图，图中箭头表示 多对一 关系 原型设计把需求设计的页面的前端样式写出来，这个项目主要仿制天猫，难点在于一些 Javascript 交互。 多层结构设计采用常见的 MVC 结构，分 dao 层 （数据库连接层）、service 层 、controller 层 和 jsp 页面 项目规划技术选型： 前端，前台使用 原生 CSS ，后台 使用 Bootsrap，统一使用 Jquery 和 Bootsrap JS ，压缩项目工期。后续后台考虑采用 MVVN 框架 （vue） 后端，这个项目采用了三种 技术 组合，都已经完成 原生 JAVA Servlet + Filter + 原生JDBCSSH结构：Spring + Struts + HibernateSSM结构：Spring + SpringMVC + Mybatis （完）","link":"/2018/05/31/yuque/small-start/"},{"title":"SSH开发 - 配合自定义注解 和 Stratus拦截器，实现 方法级粒度 用户鉴权","text":"提要本文是 小小商城-SSH版的 细节详解系列 之一，项目 github：https://github.com/xenv/S-mall-ssh 本文代码大部分在 github 中 可以找到。 有用户系统，就必须有配套的鉴权系统来确保页面不被非法访问。市面上的鉴权系统，最为成熟的就是shiro，但是体量太重，使用也不太方便，对代码的侵入型也比较强，所以我简单使用 自定义注解 和 Stratus拦截器 就实现了一个 简单 的鉴权系统，虽然不及 shiiro 稳定和功能强大，但是也足够使用，并且配置非常简单。 具体实现原理其实非常简单，先在 action 类和 方法上配置好自定义注解，然后配置一个拦截器读取这些注解，在和 session 里面的 user 比对 权限，判断是否放行即可。 在配置自定义注解时，我选择了类和方法同时配置，方法如果不配置则使用类的权限配置。 在User实体类中，用enum定义用户组 123public enum Group{ unLogin,user,admin,superAdmin;} 定义一个自定义注解 123456@Retention(RetentionPolicy.RUNTIME) // 运行时可以被获取 @Target({METHOD,TYPE}) //加载类上或者方法上面@Inherited //可以子类继承public @interface Auth { User.Group value(); //User.Group是一个enum类型，在User实体类中定义} 在 action 类中加入这个自定义注解 比如前台的 Action 中，可以在 action 类上面加一个 @Auth(User.Group.unLogin) ，这样该 action 类下面的所有方法 unLogin 用户都可以访问。对于不想要 unLogin 用户 访问 的方法，可以在那个方法上面加上 @Auth(User.Group.user) ，就会覆盖掉 类的权限配置。 配置一个拦截器实现鉴权动作 123456789101112131415161718192021222324252627282930313233public class AuthInterceptor extends AbstractInterceptor { @Override public String intercept(ActionInvocation actionInvocation) throws Exception { //获取访问页面的权限 //获取方法上的注解 Object action =actionInvocation.getAction(); String methodName=actionInvocation.getProxy().getMethod(); Auth authInMethod=action.getClass().getMethod(methodName).getAnnotation(Auth.class); //获取类上的注解 Auth authInClass = action.getClass().getAnnotation(Auth.class); //获取Enum方法的ordinal，根据大小来确定该页面权限 int pageRate = authInClass==null?0:authInClass.value().ordinal(); pageRate = authInMethod == null?pageRate:authInMethod.value().ordinal(); //获取用户的权限 int userRate = 0; User user = (User) ActionContext.getContext().getSession().get(\"user\"); if(user!=null){ userRate = user.getGroup().ordinal(); } //根据权限决定是否放行 if(pageRate&gt;userRate){ if(userRate == 0) { ServletActionContext.getResponse().sendRedirect(\"/login\"); return null; } return \"/noAuth\"; } return actionInvocation.invoke(); }} 使拦截器生效，在struts.xml中配置 1234567891011121314&lt;package name=\"basic-struts\" extends=\"struts-default\"&gt; &lt;interceptors&gt; &lt;interceptor name=\"authInterceptor\" class=\"tmall.interceptor.AuthInterceptor\" /&gt; &lt;interceptor-stack name=\"myInterceptors\"&gt; &lt;interceptor-ref name=\"authInterceptor\"/&gt; &lt;interceptor-ref name=\"defaultStack\"/&gt; &lt;/interceptor-stack&gt; &lt;/interceptors&gt; &lt;default-interceptor-ref name=\"myInterceptors\" /&gt; &lt;global-results&gt; &lt;result name=\"/noAuth\"&gt;/noAuth&lt;/result&gt; &lt;/global-results&gt;&lt;/package&gt; OK，大功告成。","link":"/2018/05/31/yuque/ssh-auth/"},{"title":"SSM开发 - 对 SpringMVC 传入参数 进行参数校验 （使用自定义AOP切面+自定义参数注解）","text":"提要 本文是 小小商城-SSM版的 细节详解系列 之一，项目 github：https://github.com/xenv/S-mall-ssm 本文代码大部分在 github 中 可以找到。 参数校验就是对用户 GET 或者 POST 传进来的参数进行校验是否合法。最简单的方法就是在每个控制器方法中，一个一个用 if 校验，但是这样效率很低。 那么，还有没有别的方法呢？SpringMVC官方推荐是使用 hibernate-validate 校验框架，但是使用起来可以说是很麻烦了，还要针对 每个 实体，再写校验器，工作量巨大。 在此，我用 自定义AOP切面 的方法，结合 自定义参数注解，非常方便的就实现了简单的参数校验（这里以非空校验为例），实现的效果如下： 123@RequestMapping(\"search\")public String search(String keyword, @Nullable String sort, Model model) throws Exception {} 对于 sort 参数，访问的时候可能并不一定会传进来，我们使用 @Nullable 进行标记（这个是我们定义的注解），否则将默认进行 非 null 检测，这样就可以大大减少空指针错误发生的几率。 有些朋友可能会问，为什么不使用SpringMVC的拦截器，而是要用 AOP 的方法呢，这里我画个图给大家解释一下： 如果是用拦截器，拦截器会在函数调用前就拦截，这样我们就没有办法做数据校验了，而AOP切点则在函数调用后，函数体调用前可以拦截，那么我们用AOP做校验就非常合适。 具体实现1.定义参数注解 （这里我只弄了个 Nullable 可空，其他不加这个默认非空）12345@Retention(RetentionPolicy.RUNTIME)@Target({PARAMETER})public @interface Nullable {} 2. 配置AOP具体的不展开讲了，网上很多，Maven两个依赖，Spring和SpringMVC都要加配置，还要加XML的域，就基本配置好了 3. 编写AOP切面 VerificationAspect.java 12345678910111213141516171819202122232425262728293031323334353637383940@Aspect@Componentpublic class VerificationAspect { /** * 声明切面 应用在，所有 Controller下的， 以Controller结尾的类中的，所有 public 方法 */ @Pointcut(\"execution(public * tmall.controller.*.*Controller.*(..))\") public void joinPointInAllController() { } /** * 切入点执行前方法 * * @param point 切入点 */ @Before(\"joinPointInAllController()\") public void checkParameter(JoinPoint point) throws ParameterException { // 获得切入方法参数 Object[] args = point.getArgs(); // 获得切入的方法 Method method = ((MethodSignature) point.getSignature()).getMethod(); // 获得所有参数 Parameter[] parameters = method.getParameters(); // 保存需要校验的args ArrayList&lt;Object&gt; argsWithoutNullable = new ArrayList&lt;&gt;(); // 对没有Nullable注解的参数进行非空校验 for (int i = 0; i &lt; parameters.length; i++) { Parameter parameter = parameters[i]; Annotation[] annotations = parameter.getDeclaredAnnotationsByType(Nullable.class); if (annotations.length &lt; 1) { argsWithoutNullable.add(args[i]); } } for (Object o : argsWithoutNullable) { if (o == null) { throw new ParameterException(\"非法请求,参数不全\"); } } }} OK，其实非常简单了。","link":"/2018/05/31/yuque/ssm-aop-verification/"},{"title":"SSM开发 - 配合自定义注解 和 SpringMVC拦截器，实现 方法级粒度 用户鉴权","text":"提要本文是 小小商城-SSM版的 细节详解系列 之一，项目 github：https://github.com/xenv/S-mall-ssm 本文代码大部分在 github 中 可以找到。 这篇文章其实和 SSH开发 | 配合自定义注解 和 Stratus拦截器，实现 方法级粒度 用户鉴权 大致一样，只是具体实现有一点区别。 有用户系统，就必须有配套的鉴权系统来确保页面不被非法访问。市面上的鉴权系统，最为成熟的就是shiro，但是体量太重，使用也不太方便，对代码的侵入型也比较强，所以我简单使用 自定义注解 和 SpringMVC 拦截器 就实现了一个 简单 的鉴权系统，虽然不及 shiiro 稳定和功能强大，但是也足够使用，并且配置非常简单。 具体实现原理其实非常简单，我们先在 controller 类和 方法上配置好权限的自定义注解，然后配置一个拦截器读取这些注解，在和 session 里面的 user 比对 权限，判断是否放行即可。 在配置自定义注解时，我选择了类和方法同时配置，方法如果不配置则使用类的权限配置。 1. 在User实体类中，用enum定义用户组123public enum Group{ unLogin,user,admin,superAdmin;} 2. 定义一个自定义注解123456@Retention(RetentionPolicy.RUNTIME) // 运行时可以被获取 @Target({METHOD,TYPE}) //加载类上或者方法上面@Inherited //可以子类继承public @interface Auth { User.Group value(); //User.Group是一个enum类型，在User实体类中定义} 3. 在 Controller 类中加入这个自定义注解比如前台的 Controller 中，可以在 这个 controller 类上面加一个 @Auth(User.Group.unLogin) ，这样该 action 类下面的所有方法 unLogin 用户都可以访问。对于不想要 unLogin 用户 访问 的方法，可以在那个方法上面加上 @Auth(User.Group.user) ，就会覆盖掉 类的权限配置。 4.配置一个拦截器实现鉴权动作 AuthInterceptor.java123456789101112131415161718192021222324252627282930313233343536public class AuthInterceptor extends HandlerInterceptorAdapter { @Override public boolean preHandle(HttpServletRequest request, HttpServletResponse response, Object o) throws Exception { if (!(o instanceof HandlerMethod)) { return true; } HandlerMethod handler = (HandlerMethod) o; //获取访问页面的权限 //获取方法上的注解 Auth authInMethod = ((HandlerMethod) handler).getMethodAnnotation(Auth.class); //获取类上的注解 Auth authInClass = ((HandlerMethod) handler).getBean().getClass().getAnnotation(Auth.class); //获取Enum方法的ordinal，根据大小来确定该页面权限 int pageRate = authInClass == null ? 0 : authInClass.value().ordinal(); pageRate = authInMethod == null ? pageRate : authInMethod.value().ordinal(); //获取用户的权限 int userRate = 0; User user = (User) request.getSession().getAttribute(\"user\"); if (user != null) { userRate = user.getGroup().ordinal(); } //根据权限决定是否放行 if (pageRate &gt; userRate) { if (userRate == 0) { response.sendRedirect(\"/login?refer=/\"); return false; } throw new AuthException(\"您已登录，但是没有权限访问这里\"); } return true; }} 对于没有权限的用户，可以跳转到登陆页面或者抛出错误即可 5.使拦截器生效，在SpringMVC.xml中配置12345&lt;mvc:interceptors&gt; .... &lt;bean class=\"tmall.interceptor.AuthInterceptor\"/&gt; ....&lt;/mvc:interceptors&gt; OK，大功告成。","link":"/2018/05/31/yuque/ssm-auth/"},{"title":"博客又重开了","text":"第一次正式开博还是2010年。那时，我在Yahoo注册了我人生中的第一个com域名，用着别扭的wordpress，每天最想做的事情就是想着安装新的插件和新的主题，写的文章有一点阅读量便欣喜不已。 然而，陆陆续续经营了一年多，我的热情逐渐退却，博客最终被关闭。 转眼已是7年过去，现在，我想重启我的博客项目。我会把我原创的一些技术文章发上来，应该大部分是以Java为主。 前几天，我在internetbs.net花了7欧注册了 coding.cx 和 notes.cx，现在暂时先启用 notes.cx 域名，以后再考虑做分离。 update: 重新注册了一个 luan.ma 用来做主域名，原域名可能会拍卖出售 值得高兴的是，我现在有了我自己写的的博客系统，虽然他只是一个html页面，但是结合 语雀 的强大后台，我相信已经足够日常使用。 关于这个博客系统的仓库在这里：https://github.com/xenv/teenyBlog 如果你对我的博客有什么建议，欢迎在下边留言。","link":"/2018/05/12/yuque/start/"},{"title":"TeenyBlog 2.0 ：使用友好、访问极速的个人静态博客解决方案","text":"新动向由于已经有了足够好用的语雀到静态博客的同步插件，该项目已废弃，新的部署方法见：https://luan.ma/post/yuque2blog/，可以非常优雅的同步语雀文章到静态博客了。 简介 TeenyBlog 2.0 是我自己摸索总结出来的一套个人静态博客的解决方案。 这套解决方案的目标是： 写博友好：支持 Markdown / 富文本，支持预览，支持复制传图和提供图床，支持 UML 图 / 思维导图 读博友好：访问速度快，稳定，界面效果良好，有 TOC 导航 维护友好：免维护，一键发布，极高可用率，极低的价格 演示： https://luan.ma 项目地址：https://github.com/xenv/teenyBlog 方案简介 博主在语雀写博客，语雀支持 Markdown / 富文本，直接预览，复制传图，图床，UML 图 / 思维导图 等功能，提供 TOC，由蚂蚁金服运营。 博主触发同步，云函数从语雀API拉取数据，并且永久静态存放在OSS中（OSS支持未备案域名） 用户访问时，经过CDN访问OSS，提供高速的访问体验 （CDN可选） 方案部署详解 写博客：在 https://yuque.com/ 注册账号并新建知识库，新建文章后，在知识库首页编辑目录，可以自由控制展示规则。 选择一个 OSS 方案，本站使用阿里云的 OSS ，选择海外机房不用备案可以直接绑定域名，如果已备案则绑定到CDN上 选择一个 云函数 方案，本站使用阿里云的函数计算，支持 HTTP访问 触发，也可以由其他事件触发。 选择一个 CDN 方案，本站主站不能备案，所以主页没有使用 CDN，但是静态资源和博文数据可以存放在 可以备案的 CDN 域名上面。本站的静态资源使用 阿里云 CDN 上传博客静态页面：https://github.com/xenv/teenyBlog/blob/master/index.html 到 OSS，并且设置为首页 修改 title 和 首页数据的 json 等信息 静态页面仅供演示，所以仅有首页，内页跳转到语雀，有能力的同学完全可以根据 语雀API 开发内容页等页面 能显示博文数据的核心在于：从语雀拉取了博文数据的 json，并且放在OSS中，我们的静态页面就可以从 JSON获取到数据，然后使用 VUE 渲染出来。 新建云函数，选择 HTTP 访问触发，我提供一下环境为 Python 3.6 的同步代码： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263import jsonimport oss2import loggingimport requests# configyuque_auth_token = 'YXDQoZMhHxNw1zJ+bIRZCL5KVOOlj1OD' # 语雀后台取得，可选yuque_path = \"page/luan.ma\" # 语雀的用户号/仓库号aliyun_auth_access_key = 'LTAITMKYkxY' # https://ram.console.aliyun.com/ 新建账号并授权 OSS 权限aliyun_auth_access_secret = 'TbiZpQRPuDGE68IT'aliyun_oss_endpoint = 'oss-cn-shenzhen-internal.aliyuncs.com' # OSS 区域：https://help.aliyun.com/document_detail/31837.htmlaliyun_oss_bucket = 'nazhumi-static' # OSS Bucket 名aliyun_oss_path = \"luanma/list.json\" # OSS 博文数据路径# The main functiondef handler(environ, start_response): logger = logging.getLogger() logger.info('start sync work') endpoint = aliyun_oss_endpoint auth = oss2.Auth(aliyun_auth_access_key, aliyun_auth_access_secret) bucket = oss2.Bucket(auth, endpoint, aliyun_oss_bucket) url = 'https://yuque.com/api/v2/repos/' + yuque_path + '/toc' try: main_html = get_data(url) main_json = json.loads(main_html) for item in main_json[\"data\"]: if len(item[\"slug\"]) &gt; 1 and \"://\" not in item[\"slug\"]: item_html = get_data(\"https://yuque.com/api/v2/repos/\" + yuque_path + \"/docs/\" + item[\"slug\"]) item_date = json.loads(item_html)[\"data\"][\"updated_at\"] item[\"date\"] = item_date.split(\"T\")[0] bucket.put_object(aliyun_oss_path, json.dumps(main_json)) response_body = { 'status': 'success' } except Exception as e: response_body = { 'status': 'fail' } status = '200 OK' response_headers = [('Content-type', 'text/json')] start_response(status, response_headers) return [json.dumps(response_body).encode()]# get url of contentdef get_data(url): headers = { 'User-agent': 'aliFunction/0.01', 'Content-Type': 'application/x-www-form-urlencoded', 'X-Auth-Token': yuque_auth_token } html = requests.get(url, headers=headers).content return html 开启CDN，绑定域名到CDN。不开启CDN则绑定域名到OSS。 修改 index.html 中的 vue.min.js 和 list.json 的路径为你的 OSS 路径。 更新博文后，访问云函数提供的地址，即可同步语雀数据到 OSS。如果是语雀企业用户，则可以配置 WebHook。 图片演示首页通过语雀后台完全可定制： 可视化 Markdown 后台 云函数后台","link":"/2018/07/18/yuque/teenyblog/"},{"title":"教程：静态博客使用语雀编辑器","text":"写在前面语雀 是一款非常好用的知识管理网站（类似 GitBook)，它的编辑器非常好用，而且支持导出 Markdown，这篇文章是教你如何使用语雀的编辑器写静态博客。这里的静态博客用了 Hexo，Jekyll 也是没有问题的。演示（我的博客） 创建 Hexo 博客已经有 Hexo 博客的可以跳过。如果你是 Jekyll ，也可以跳过。 安装 Node.js 安装 Hexo 脚手架 1npm install -g hexo-cli 初始化一个博客 123hexo init &lt;folder&gt;cd &lt;folder&gt;npm install 其他设置和命令见：https://hexo.io/zh-cn/docs/ 安装语雀文章下载插件yuque-hexo 是一个 Node.js 环境下的语雀下载器，使用 npm 安装 安装 yuque-hexo 1npm i -g yuque-hexo 注册语雀，创建知识库，获得你的个人路径和知识库的名字，比如我的博客的知识库是 https://www.yuque.com/page/luan.ma 在 Hexo 博客的目录下面的 package.json 中，进行下面的配置 12345678910{ \"name\": \"your hexo project\", //如果原来已经有这个不用再加了，直接加下面的就可以 \"yuqueConfig\": { \"baseUrl\": \"https://www.yuque.com/api/v2\", \"login\": \"page\", \"repo\": \"luan.ma\", \"mdNameFormat\": \"slug\", \"postPath\": \"source/_posts/yuque\" }} 如果不是 Hexo 博客，则需要按照上面的文件保存一个 package.json 到博客目录，并且配置 postPath 为正确的文章目录 同步文章 1yuque-hexo sync PS: 插件支持 Front-matter，在语雀写文章的时候直接写在前面，然后插入一条分割线即可，不写也没问题：123tags: [Hexo]categories: 教程date: 2018-10-05 10:43:50 启动/部署 Hexo 博客 本地启动（调试用） 1hexo s 生成 html 不部署 1hexo g 自动上传到服务器/静态空间/git （部署） 先找到一个部署插件 在配置文件中配置好相关的账号密码 在 hexo 中生成 HTML 并且部署1hexo g -d 静态博客空间选择 Github Pages： 方便，不太稳定，Git部署 Coding.net Pages： 需要挂一个链接 或者 付费，速度尚可，Git部署 腾讯云 COS + 腾讯云 CDN：需要备案，速度极快，COS 插件部署 自有服务器：可定制，速度一般 ，支持多种方式部署 写在后面其实这篇文章干货不多，主要是应某网友的要求，顺便把我的 TenneyBlog 做个了结。核心是把 yuque-hexo 这个东西介绍给大家。这个插件由阿里巴巴的同学开发，我也做了一些微小的贡献。本博客目前也是使用这个方案同步语雀的文章。 当然，关于 Hexo 皮肤、评论插件等等玩法也要折腾很久，我就不在这篇文章里面说了。","link":"/2018/10/05/yuque/yuque2blog/"},{"title":"Java NIO、BIO、 AIO 与 同步、阻塞、非阻塞、异步IO 简析","text":"写在前面我相信大部分人看到这些名词，都是一头雾水的，如果你去搜索引擎搜索，那么恭喜你，你又会被各种文章中的高大上的名词搞得云里雾里。那么，我们应该怎么理清这么名词之间的关系呢？ 所谓 同步/异步/阻塞/非阻塞IO ，是指操作系统中的对IO处理的不同方法，而 Java 对这些不同操作方法做了一些包装，由此有了 BIO / NIO / AIO 几种操作接口。 我不想复制一些高大上的概念，只是想尽量好好说话，说清楚他们之间的关系。 需求 有 A、B、C、D四个线程可以生产文件，假设他们的返回的文件是一样的，对应我们的服务端 有 E、F、G、H 四个线程在随机时间向服务端上传一个文本，并且要求返回一个文件，对应我们的客户端 服务端和客户端可以在同一个操作系统中，也可以是在网络中。在网络中，客户端的请求会接入到服务端的操作系统内核，所以和在同一个操作系统中没有太大区别。如果在网络中，那么这可能就是一个 TCP/HTTP 的模型。 问题：要怎么设计一个程序来的完成上面的操作？ 系统IO缓冲区在讲之前，还要明白系统内核中的IO缓冲区的概念。在现实生活中，一个人想要把想法告诉另外一个人，有两种方法，一种是靠嘴说给他听，对方要不停的确认，这样是很慢的。另外一种是直接写一篇10页的文稿一次性发给另外一个人，另外一个人有问题再重写一份文档把所有问题写在上面，那么多了这个文档的缓冲区，就可以提高交流的效率。 在系统里面，对两个用户之间的传输操作，首先会建立一个连接，然后会创建一个专用的缓冲区。缓冲区有四个状态。 我们现在有一个情景，就是用户端E向服务端A在随机时间上传一份文件。缓冲区会经历这四个状态。 缓冲区空：E心情不好，还没传文件，这个时候缓冲区是空的 缓冲区非空：E开始往缓冲区里面传数据了，现在缓冲区是非空的，A知道之后会来查收 缓冲区满：如果A一直没查收这个文件，或者A的查收速度没有E上传的速度那么块。那么缓冲区会被填满。这个时候E知道了，就先等着。 缓冲区非满：E等了一段时间，A终于处理了一些E上传的数据了，缓冲区又有空间了，缓冲区把状态设置为缓冲区非满，E知道之后，又可以往缓冲区传数据了。 最终，经过上面的“博弈”，缓冲区最终为空，文件传输完成。接下来可能又要有下一轮文件传输。我们的几个IO模型就是围绕着上面的博弈展开的。 同步关于 A 如何查收 缓冲区中的内容，我们有同步和异步两种模式。绝大部分应用都是同步查收的。就是说，A 主动 从缓冲区 剪切、粘贴 到自己的用户空间里面。剪切、粘贴的时间CPU要等着啥也不干，这个过程是比较费时的，但是也没有办法。 同步阻塞我们来讨论另外一个问题，就是 A 怎么知道 E 要来传文件呢？换一种说法就是，A怎么知道缓冲区由空变成非空了，要工作了。 阻塞就是这样一种方法：A在缓冲区非空的时候，就把自己阻塞住（休眠），等着，啥也不干，一直到缓冲区非空了，系统就叫醒A，A这个时候就会从缓冲区查收数据了。A处理完之后又把自己阻塞住，等待下一个非空状态。 这样做的坏处是什么呢？就是 E、F、G、H 想在随机时间 往 服务端传文件，建立了连接之后，服务端上面就要有 A、B、C、D 四个线程等着啥也不干。但是我们知道，创建线程是需要消耗内存的，这样子客户端多了之后，系统内存就捉襟见肘了。 同步非阻塞1.0 版：忙轮询非阻塞和阻塞相反。A 是不阻塞（休眠）的，他会定时定点就检查一下缓冲区是不是非空（可读）了，如果可读就可以工作了。 这样做有一个好处，就是 A 可以一次性把 E、F、G、H 接进来，创建四个缓冲区。然后把这些连接保存成一个 list ，然后 A 定时就检查这个 list 中的连接的缓冲区的状态。这样一个 A 就可以处理多个客户端，处理效率就提高了。 这种一条线程接进来多个客户端的操作，也叫IO多路复用。 但是如果是由应用层来遍历，也未免有点太傻了，如果 E、F、G、H一直不传文件，A就要一直耗费CPU去定时查询，所以这个傻事要由操作系统统一去干。 2.0版： select、poll我们把定时查询这个任务就交给系统去做，我们只需要把我们关心的用户的连接ID（缓冲区）告诉系统。比如还是上面的例子，A先自己把自己阻塞住，当E、F、G、H没有活干的时候，就一直保持阻塞状态。当E、F、G、H其中之一往系统内核的缓冲区上传了数据，那么，系统就会唤醒A，并且告诉他，起来干活了。不过这个时候 A 对于要查收谁的文件还是一脸懵逼的，只能再自己去遍历一遍所有连接的缓冲区，看看哪个缓冲区的状态是非空的，然后再读。这就是 Select 的大致原理。 这样做避免了 1.0 版的CPU空转，但是唤醒A之后，A还必须自己去遍历一下所有客户端连接的列表，是一个 O(n) 的操作，所以这个列表不能太长，select 简单粗暴的就定为了 1024 个。 也就是说默认一个线程只能处理1024个客户端。poll 改进了 list 的储存结构，这样就可以存更多的连接，不过也是治标不治本呀。 3.0版： epollepoll 是 select 的改进 使用了更优的数据结构来管理连接列表，使得定位的时候更快 唤醒 A 之后，会传给他缓冲区非空的连接，A直接使用即可。而不只是告诉A醒来，让A自己去找。所以这里是一个 O (1) 的复杂度。 这是目大多数网络应用的底层实现。 4.0版： EventloopEventloop并不是操作系统底层的实现，但是在应用层提供了一种更高效的复用思路。 在 传统 epoll 应用中，普通线程只负责客户端的连接的读写操作，如果客户端没有操作，那么线程会被阻塞。而我们要做一些额外的事情可能就要再开线程。 那么，我们还有另外一种复用线程的思路，就是 Eventloop，我们有一个比较小的线程池，每个线程 都有一个 Eventloop， 上面有个事件队列，一方面，Eventloop尝试epoll，并且设置阻塞的超时时间，如果到达时间，仍没有客户端读写事件，就先处理事件队列上面的其他事件。我们可以打包一些要做的函数进事件队列，那么本来是负责 Epoll 的线程在本来应该阻塞的时候，还可以做些别的任务。这样就减少了整个系统的线程数量。 当然，要注意，我们有时候也叫 Eventloop 这种实现是异步的，但是和我们整篇文章讲的同步异步并不是在一个区域，我们讲的是系统级的连接的IO操作。而 Eventloop 则是一种在应用级的多任务调度方式。 异步我们之前说了，在系统IO中，对于同步异步的概念，是说 A 如何查收 缓冲区中的内容。 而异步的意思是说，调用之后，马上返回一个内存引用，这个引用什么时候填充数据我们并不知道，但是我们可以告诉这个引用填充完数据之后应该干什么。然后这个事件会打包进任务队列，在不定时间执行。 异步IO的方式，我们的A就可以先开好一个用户空间的内存区域，然后把查收之后要做的事情打包成一个函数，全部告诉给内核，然后内核会自动帮你把数据从内核缓冲区复制到你指定的用户空间，然后调用你指定的函数。 这样，在IO读写的时候，阻塞的是系统内部的线程，而不是我们的A线程，这样A线程的处理效率会提高，也不用一直在阻塞和继续中徘徊。当然，也就没有阻塞还是非阻塞的区别了。 JDK 在 linux上面的AIO实现方法是去维护一个线程池（Linux的异步IO接口不给力）。而在 Windows 上面则有 IOCP 的异步IO 黑科技，主要是在IIS上面使用。 然而，因为从内核缓冲区复制到用户空间这个地方的时间仍然是没有办法避免的，所以 IOCP 比 epoll 的 Eventloop 在性能上其实并没有太大优势，只是说是内核做异步在线程调度上面更有优势，可以节省一些CPU使用。 JDK实现BIOBIO就是同步阻塞IO的实现，就是最传统的java.io 包下面的 ServerSocket 的写法。 NIO是同步非阻塞IO的实现，Windows下面使用底层的 select ，Linux 下面使用底层的 epoll也就是普通java.nio 的用法。 AIOAIO是异步IOCP的实现，是 java.nio.channels.Asynchronou* 下面的包的调用在Linux使用JDK自建线程池，在 Windows 下面使用 IOCP，不过据说还是有些 bug 应用实现NettyNetty默认是使用 NIO 底层 （同步非阻塞）。 但是在应用层面上，使用 Eventloop 的异步实现，即用一个比较小的线程池同时处理用户端的连接、数据复制，解析数据和执行业务代码。通常，Netty 已经帮我们将相关客户端的数据读取和解析（比如解析HTTP请求），我们只需要写具体的业务代码即可。通常，在业务代码中，我们应该尽可能少的使用同步代码，数据库读取也使用异步NIO连接（比如，使用 NIO 客户端 连接 MongoDB 或者 Redis ），从而最大化压缩线程因阻塞而浪费的时间。而确实可能会导致阻塞的耗时操作，也用异步封装成事件，发到另外的大线程池中。这样可以用较少的线程完成较多的任务，同时阻塞的时间尽可能小，以达到性能最大化的目的。 Netty曾经也尝试过 AIO 作为底层，不过最后因为性能比NIO差，和兼容性的问题而放弃。为什么差我们也可以做一个猜测，就是 Netty 有一个 Eventloop 线程池 ，和操作系统的AIO线程池没有很好兼容，反而增多更多性能损耗。 Tomcat Tomcat 默认是使用 NIO 底层（同步非阻塞），并且也是异步实现（Acceptor 和 Poller 和 Netty 的 Eventloop 模型如出一辙），我们跑的 SpringBoot 等等都可以跑在 Tomcat 上面，速度理论上是不错的。 可惜在 Tomcat 对于每一个请求，将我们整个 Servlet 、管道、监听器、拦截器 所有东西都打包在一起（当然里面全部都是同步的代码），形成一个超级大的 Runable ，发到线程池上面，导致整个处理请求的过程中多处都要同步等待（比如读取数据库，一般使用同步的方式，如 JDBC 是典型的同步应用），而等待的时间是要占着当前线程的，导致同时处理的任务量过大时，Tomcat 性能非常差。 这也告诉我们，NIO并不是解决所有问题的万能药，如果我们在 Netty 中运行大量会阻塞很久的同步的代码，也会导致 Netty 性能大幅下降。 其他另外，Nginx 、 Nodejs、Redis 网络底层都是 select 或者 epoll，也就是说，在系统层面，IO是同步非阻塞的，只是在应用的任务调度层面，是异步的。而异步IO阵营可以说是门前冷落了，IOCP 只有 IIS 在大规模使用。 参考资料https://www.zhihu.com/question/20122137/answer/14049112https://cloud.tencent.com/developer/article/1005481https://javadoop.com/post/tomcat-nio","link":"/2018/08/08/yuque/io-model/"},{"title":"Java Lambda 解析和使用技巧","text":"lambda是包着一个函数的对象lambda表达式非常简洁优雅。是把动态语言的特性嫁接到静态语言的一个典范。 在java中，我更加愿意认为lambda实际上是是包着一个函数的对象，我们在使用lambda表达式的时候，实际上定义了一个闭包的函数对象，这是lambda最大的意义所在。在过去，我们在函数之间传递一个函数，必须手动把它包装成类的对象，并用接口加以规范。现在，我们可以直接用lambda自动生成一个这样的对象。 如果你用过 Javascript/Python，你可以把刚刚定义的函数当做对象传给别的函数。现在，你用 lambda 也可以在 java 的里面传参时把函数用lambda形式“打包”传给别的函数，并且符合强类型的面向对象要求。 我们先用面向对象的方法理解 lambda 函数，他首先是一个对象，但是不需要我们手动new，他的类型是 一个接口 12345678910111213141516171819202122232425262728// 这是 Runnable 接口public interface Runnable { void run();}// 在以前，我们可能要这样创建一个 Runnable 对象（当然也可以用匿名内部类）class taskClass implements Runnable { @Override public void run() { System.out.println(\"test\"); }}Runnable task = new taskClass();// 对象可以使用接口的方法task.run(); // 输出 test// 现在，有了 lambda，系统用了些黑魔法，自动实例化了类，并且给我们创建好了对象// 其实，这个task不是内部类而真的是一个私有的函数，是的，编译器就是可以为所欲为Runnable task = () -&gt; { System.out.println(\"test\");};// 你可以表面地理解成，系统把 小括号 和 大括号的内容，复制粘贴到上面去了 看到这里，你可能会问，系统依据什么来创建这个函数对象呢？如果一个接口里面有许多方法，我们的lambda表达式应该应用到（复制、粘贴到）哪个方法上面呢？lambda的输出类型怎么定义呢？ 答案就是，这种接口，有且只能有一个抽象方法，系统会自动找到这一个方法（虽然这样看起来有些随意）作为创建这个函数对象的模板。 lambda传参数和返回值和 Runnable 接口一样，JDK还给我们带来了几个比较常见的接口：如 Consumer 接口 和 Supplier 接口 12345678910111213141516171819// 这个接口的特点是，有一个参数，无返回值public interface Consumer&lt;T&gt; { void accept(T t);}// 用 lambda创建一个 consumer 对象Consumer&lt;String&gt; consumer = (String item) -&gt; { System.out.println(item);};// 这个接口的特点是,无参数，有返回值public interface Supplier&lt;T&gt; { T get();}// 用 lambda 创建一个 supplier 对象Supplier&lt;String&gt; supplier = () -&gt; { return \"test\";} java.util.function 下有大量JDK8带来的接口 Predicate&lt;T&gt; – a boolean-valued property of an object | 输入T，返回 boolean Consumer&lt;T&gt; – an action to be performed on an object | 输入 T，返回void Function&lt;T,R&gt; – a function transforming a T to a R | 输入 T 返回 R Supplier&lt;T&gt; – provide an instance of a T (such as a factory) | 输入() 返回T UnaryOperator&lt;T&gt; – a function from T to T | 输入 T 返回 T BinaryOperator&lt;T&gt; – a function from (T, T) to T | 输入 (T,T) 返回 T IntSupplier 等基础数值非泛型接口 我们在使用的时候，只用关心接口下面的唯一抽象方法的输入值和返回值即可，不用太关心名字 lambda 的语法糖 如果函数体只有一行，不需要大括号 如果函数的参数只有一个，不需要小括号 如果函数的参数可以由上下文推导，则不需要写参数类型 如果函数体只有一行，不用写 return 这四个比较好理解，比如，这样写是合法的：12Consumer&lt;String&gt; consumer = item -&gt; System.out.println(item);Supplier&lt;String&gt; supplier = () -&gt; \"test\"; 还有我个人感觉做的比较随意的 双冒号 :: 语法糖，这种形式叫做方法引用（method references） 引用静态方法 Integer::sum 引用某个对象的方法 list::add 引用某个类的方法 String::length 引用构造方法 HashMap::new 比如，原来我们这么写1Consumer&lt;String&gt; consumer = item -&gt; System.out.println(item); 现在用双冒号语法可以这么写，这样写也有好处，让你看起来这更像是传了一个方法进去1Consumer&lt;String&gt; consumer = System.out::println; lambda局部变量使用机制lambda中使用上下文定义的局部变量，必须是 final的，当然，如果你忘了加final，编译器会帮你自动加上。当然，如果是类变量则没有这个限制 1234String x = \"Hello \"; // 如果下文有 lambda 使用了 x，这句等价于 final String x = \"Hello \"x = \"test\"; // 这句非法，无法通过编译Function&lt;String,String&gt; func1 = y -&gt; y+x; System.out.println(func1.apply(\"luan.ma\")); lambda底层实现Lambda表达式通过invokedynamic指令实现，书写Lambda表达式不会产生新的类。他在 class 文件中是一个私有函数1234567public class MainLambda { public static void main(String[] args) { new Thread( () -&gt; System.out.println(\"Lambda Thread run()\") ).start();; }} 12345678910111213141516171819// javap -c -p MainLambda.classpublic class MainLambda { ... public static void main(java.lang.String[]); Code: 0: new #2 // class java/lang/Thread 3: dup 4: invokedynamic #3, 0 // InvokeDynamic #0:run:()Ljava/lang/Runnable; /*使用invokedynamic指令调用*/ 9: invokespecial #4 // Method java/lang/Thread.\"&lt;init&gt;\":(Ljava/lang/Runnable;)V 12: invokevirtual #5 // Method java/lang/Thread.start:()V 15: return private static void lambda$main$0(); /*Lambda表达式被封装成主类的私有方法*/ Code: 0: getstatic #6 // Field java/lang/System.out:Ljava/io/PrintStream; 3: ldc #7 // String Lambda Thread run() 5: invokevirtual #8 // Method java/io/PrintStream.println:(Ljava/lang/String;)V 8: return} 所以，在使用层面，lambda中的 this 就是主类的 this，和主类的函数没有太大区别。而匿名内部类或者是内部类在使用中则要注意this的指向问题。 JDK 数据结构中使用 lambda JDK中的数据结构 加入的 支持 lambda 的方法列表： 接口名 Java8新加入的方法 Collection removeIf() spliterator() stream() parallelStream() forEach() List replaceAll() sort() Map getOrDefault() forEach() replaceAll() putIfAbsent() remove() replace() computeIfAbsent() computeIfPresent() compute() merge() Collection: stream()方法这是最强大的支持lambda的方法，List所有lambda方法在 stream()中都可以完成，而且支持 set 和 queue他还有一个可以自动多线程拆分、执行的兄弟 .parallelStream() Tips: 上下限通配查看方法看之前，我先说一下方法里面各种上下限通配的查看方法：&lt;? extends T&gt;用于方法返回，参数类型上界是T，因此子类不能随意传入，只读&lt;? super T&gt; 用于方法传入，参数的类型下界是 T，因此若传出只能是 Object 类型&lt;T&gt; 既要传入，又要返回? 既不能传入，也不能返回 list: forEach()方法：void forEach(Consumer&lt;? super E&gt; action)作用是对容器中的每个元素执行action指定的动作，其中Consumer是个函数接口，里面只有一个待实现方法void accept(T t)12345ArrayList&lt;String&gt; list = new ArrayList&lt;&gt;(Arrays.asList(\"I\", \"love\", \"you\", \"too\"));list.forEach( str -&gt; { if(str.length()&gt;3) System.out.println(str); }); 遍历，并对每一项执行一个函数。forEach方法和原来的for()遍历，看起来更加简洁 list: removeIf()方法 boolean removeIf(Predicate&lt;? super E&gt; filter)删除容器中所有满足filter指定条件的元素，其中Predicate是一个函数接口，里面只有一个待实现方法boolean test(T t)。传统，我们需要要迭代器来迭代删除数据，现在有了 removeIf 函数，我们可以传入一个 返回值 为 true 或者 false d lambda 表达式，如果 true，那么元素就会被删除 1list.removeIf(str -&gt; str.length()&gt;3); list: replaceAll()方法 void replaceAll(UnaryOperator operator)对数据集合的每个数据执行一个方法。在之前，我们需要遍历，get出来，转换，再set回去，现在我们可以直接用 lambda 实现12345list.replaceAll(str -&gt; { if(str.length()&gt;3) return str.toUpperCase(); return str;}); list: sort()方法 void sort(Comparator&lt;? super E&gt; c)排序方法，输入两个对象，返回一个int值，根据正负来确定排序位置1list.sort((str1, str2) -&gt; str1.length()-str2.length()); map: forEach()方法 void forEach(BiConsumer&lt;? super K,? super V&gt; action)作用是对Map中的每个映射执行action指定的操作，其中BiConsumer是一个函数接口，里面有一个待实现方法void accept(T t, U u)。原来的方法非常繁琐，现在变得非常简单1map.forEach((k, v) -&gt; System.out.println(k + \"=\" + v)); map: replaceAll()方法 replaceAll(BiFunction&lt;? super K,? super V,? extends V&gt; function)作用是对Map中的每个映射执行function指定的操作，并用function的执行结果替换原来的value，其中BiFunction是一个函数接口，里面有一个待实现方法R apply(T t, U u) 1map.replaceAll((k, v) -&gt; v.toUpperCase()); map: merge()方法 merge(K key, V value, BiFunction&lt;? super V,? super V,? extends V&gt; remappingFunction) 如果Map中key对应的映射不存在或者为null，则将value（不能是null）关联到key上； 否则执行remappingFunction，如果执行结果非null则用该结果跟key关联，否则在Map中删除key的映射． 传入的是key, value，以及一个备选方案：有两个值要如何处理 1map.merge(key, newMsg, (v1, v2) -&gt; v1+v2); map: compute() 方法 compute(K key, BiFunction&lt;? super K,? super V,? extends V&gt; remappingFunction)把remappingFunction的计算结果关联到key上，如果计算结果为null，则在Map中删除key的映射． 传入key， value由旧值的函数计算得到 要实现上述merge()方法中错误信息拼接的例子，使用compute()代码如下： 1map.compute(key, (k,v) -&gt; v==null ? newMsg : v.concat(newMsg)); map: computeIfAbsent()方法 V computeIfAbsent(K key, Function&lt;? super K,? extends V&gt; mappingFunction)只有在当前Map中不存在key值的映射或映射值为null时，才调用mappingFunction，并在mappingFunction执行结果非null时，将结果跟key关联． 不存在才加，存在直接跳过 Function是一个函数接口，里面有一个待实现方法R apply(T t)． computeIfAbsent()常用来对Map的某个key值建立初始化映射．比如我们要实现一个多值映射，Map的定义可能是Map&lt;K,Set&lt;V&gt;&gt;，要向Map中放入新值，可通过如下代码实现： 1234567891011Map&lt;Integer, Set&lt;String&gt;&gt; map = new HashMap&lt;&gt;();// Java7及以前的实现方式if(map.containsKey(1)){ map.get(1).add(\"one\");}else{ Set&lt;String&gt; valueSet = new HashSet&lt;String&gt;(); valueSet.add(\"one\"); map.put(1, valueSet);}// Java8的实现方式map.computeIfAbsent(1, v -&gt; new HashSet&lt;String&gt;()).add(\"yi\"); 使用computeIfAbsent()将条件判断和添加操作合二为一，使代码更加简洁． map: computeIfPresent()方法 V computeIfPresent(K key, BiFunction&lt;? super K,? super V,? extends V&gt; remappingFunction)只有在当前Map中存在key值的映射且非null时，才调用remappingFunction，如果remappingFunction执行结果为null，则删除key的映射，否则使用该结果替换key原来的映射． 不存在直接跳过，存在才插进去 这个函数的功能跟如下代码是等效的： 1234567891011// Java7及以前跟computeIfPresent()等效的代码if (map.get(key) != null) { V oldValue = map.get(key); V newValue = remappingFunction.apply(key, oldValue); if (newValue != null) map.put(key, newValue); else map.remove(key); return newValue;}return null; 参考资料深入理解Java函数式编程和Streams API","link":"/2018/06/26/yuque/lambda/"},{"title":"Netty 处理流程简析（附流程图）","text":"概述入坑 Netty 已有月余，主要还是接触 Vert.x ，并未有太多机会直接写 Netty。也尝试在网上看了许多的源码解析，但是总是没有一个提纲来完整的表述整个 Netty 的完整处理流程。我这里尝试用流程图的方法，解析 Netty 主要的几个Netty主要的处理流程。主要是主流程和Pipeline对于 ByteBuf、各种 Decoder ，我这里也不再详细解析，有兴趣可以再看网上的解析。 Netty运行时处理请求的流程 说明： 每个 Eventloop 都有自己的一个 Selector，我为了画图方便，改为共用一个 Selector Boss Eventloop负责 ACCEPT 事件，他在启动的时候向 Selector 注册 ACCPET 事件和 ServerChannel，并且绑定端口 Work EventloopGroup 是一组 Work Eventloop 的集合，数量默认为 CPU 核心数 *2 Work Eventloop 本质上是一个线程，他有一个死循环，执行两种事件：READ事件和自己任务队列上面的事件 Work Eventloop 的任务队列上面的事件是可以在任何地方提交加入（通过 Future/Promise 的 addListener 方法提交任务） Pipeline 是在我们启动的 Netty 的时候指定的，是我们的任务代码 Buffer 是缓冲区，缓冲我们的数据，并且一次写入。 Channel 是和用户连接的桥梁，往 Channel 写数据就是往用户电脑写数据 Pipeline 处理时可以选择同步模式还是异步模式，但无论如何最终都要刷写 Buffer ，最后要结束数据流。 Netty Pipeline 流程InBound 操作的流水线Inbound的方法一般由系统Netty帮我们调用ChannelRegister: 客户 Channel 注册到 Eventloop 里面会发送事件 （第一次连接）ChannelActive: 客户 Channel 连接的时候Channel会发送事件 （从未连接到已连接）ChannelRead: 客户的数据已经存了一部分到系统缓冲区的时候会发送事件 （从未发送数据到已发送数据）ChannelReadComplete： 缓冲区里面已经没有数据会发送事件（从发送数据到发送数据完成）调用的流程是一致的，主要用到的是 ChannelRead 说明： HandlerContext是 Pipeline 的每一个节点，从而组成一个双向链表结构。每个 HandlerContext 包含以下内容： 自定义的Handler对象 用户 Channel 关联的 Eventloop Inbound 和 OutBound 的触发器 ByteBuffer 内存分配器 添加 Channel Handler 的方法 在 Bootstrap 中 .childHandler() ch.pipeline().addLast() 可以添加 Inbound 和 OutBound OutBound操作流水线一般是主动调用，而不是Netty自动调用bind 操作connect 操作disconnect 操作read 操作 （一般不用，用Inbound的自动Read）write 操作deregister 操作 异常处理流水线 业务中的流水线这里只是给一个参考","link":"/2018/08/26/yuque/netty-flow/"},{"title":"Spring 核心：Spring AOP 用法和原理简析","text":"概述AOP(Aspect Oriented Programming) 面向切面编程，实质上是对我们的对象进行增强，并且提供良好的管理机制。对于对象增强，可以有以下几种方法 装饰器模式，比如JDK中的I/O流 1InputStream inputStream = new LineNumberInputStream(new BufferedInputStream(new FileInputStream(\"\"))); 静态代理模式 适配器模式 动态代理，包括 Proxy 和 CGLIB 等方法进行动态代理 SpringAOP 是一套 AOP 的解决方案，他比传统的对象增强更容易管理和扩展。在对象增强上，它的规则是：基于动态代理来实现。默认地，如果使用接口方法的，用 JDK 提供的动态代理实现，如果没有接口，使用 CGLIB 实现。SpringAOP 基于 IOC 容器，动态代理之后，会把原对象替换成动态代理的对象。 概念Advisor 是 AOP 的一个概念，他是 保存AOP配置 的一个单位 Advice：方法拦截逻辑，可控制该方法执行前和方法执行后或者出现异常时候的执行的逻辑 PointCut： 在哪些地方的方法应用拦截 Advisor__： __里面有且只有一个 Advice，可以对多个 PointCut 执行 Advice 方法。 注解配置 Spring AOPSpringAOP 和 AspectJ 没多大关系，而仅仅是使用了 AspectJ 中的概念，包括使用的注解也是直接来自于 AspectJ 的包（有点迷）。 依赖12345&lt;dependency&gt; &lt;groupId&gt;org.aspectj&lt;/groupId&gt; &lt;artifactId&gt;aspectjweaver&lt;/artifactId&gt; &lt;version&gt;1.8.11&lt;/version&gt;&lt;/dependency&gt; 或者在 SpringBoot1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-aop&lt;/artifactId&gt;&lt;/dependency&gt; 注解注解开启，在Main 类上面标上这个注解1@EnableAspectJAutoProxy 在 配置文件Bean 上 打上 @Aspect1@Aspect 配置 PointCut12345@Aspectpublic class SystemArchitecture { @Pointcut(\"execution(* transfer(..))\")// the pointcut expression private void anyOldTransfer() {}// the pointcut signature} 一些配置规则12345678910@Pointcut(\"execution(* transfer(..))\")// 方法签名@Pointcut(\"within(com.javadoop.springaoplearning.service..*)\")// 包下所有类的所有方法@Pointcut(\"execution( .*(..))@annotation(com.javadoop.annotation.Subscribe)\")// 指定注解的所有方法@Pointcut(\"bean(*Service)\")// 指定 bean 名的所有方法// 通常 \".\" 代表一个包名，\"..\" 代表包及其子包，方法参数任意匹配使用两个点 \"..\" 一些实践中的配置1234567891011121314151617181920212223@Aspectpublic class SystemArchitecture { // web 层 @Pointcut(\"within(com.javadoop.web..*)\") public void inWebLayer() {} // service 层 @Pointcut(\"within(com.javadoop.service..*)\") public void inServiceLayer() {} // dao 层 @Pointcut(\"within(com.javadoop.dao..*)\") public void inDataAccessLayer() {} // service 实现，注意这里指的是方法实现，其实通常也可以使用 bean(*ServiceImpl) @Pointcut(\"execution(* com.javadoop..service.*.*(..))\") public void businessService() {} // dao 实现 @Pointcut(\"execution(* com.javadoop.dao.*.*(..))\") public void dataAccessOperation() {}} 配置 Advice12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758@Aspectpublic class AdviceExample { // 这里会用到我们前面说的 SystemArchitecture // 下面方法就是写拦截 \"dao层实现\" @Before(\"com.javadoop.aop.SystemArchitecture.dataAccessOperation()\") public void doAccessCheck() { // ... 实现代码 } @Before(\"com.javadoop.springaoplearning.aop_spring_2_aspectj.SystemArchitecture.businessService()\") public void logArgs(JoinPoint joinPoint) { System.out.println(\"方法执行前，打印入参：\" + Arrays.toString(joinPoint.getArgs())); } @AfterReturning(\"com.javadoop.aop.SystemArchitecture.dataAccessOperation()\") public void doAccessCheck() { // ... } @AfterReturning( pointcut=\"com.javadoop.aop.SystemArchitecture.dataAccessOperation()\", returning=\"retVal\") public void doAccessCheck(Object retVal) { // 这样，进来这个方法的处理时候，retVal 就是相应方法的返回值，是不是非常方便 // ... 实现代码 } // 异常返回 @AfterThrowing(\"com.javadoop.aop.SystemArchitecture.dataAccessOperation()\") public void doRecoveryActions() { // ... 实现代码 } @AfterThrowing( pointcut=\"com.javadoop.aop.SystemArchitecture.dataAccessOperation()\", throwing=\"ex\") public void doRecoveryActions(DataAccessException ex) { // ... 实现代码 } // 注意理解它和 @AfterReturning 之间的区别，这里会拦截正常返回和异常的情况 @After(\"com.javadoop.aop.SystemArchitecture.dataAccessOperation()\") public void doReleaseLock() { // 通常就像 finally 块一样使用，用来释放资源。 // 无论正常返回还是异常退出，都会被拦截到 } // 感觉这个很有用吧，既能做 @Before 的事情，也可以做 @AfterReturning 的事情 @Around(\"com.javadoop.aop.SystemArchitecture.businessService()\") public Object doBasicProfiling(ProceedingJoinPoint pjp) throws Throwable { // start stopwatch Object retVal = pjp.proceed(); // stop stopwatch return retVal; }} advisor会由Spring给我们生成。 原理解析在 Spring中，Bean 初始化结束后，会对每一个 bean 调用一次实现 BeanPostProcessor 接口的 Bean postProcessAfterInitialization() 方法。 当我们通过注解配置 AOP （XML差不多），Spring 会 给我们注册一个 AnnotationAwareAspectJAutoProxyCreator 的 Bean，这个 Bean 就实现了 BeanPostProcessor 接口 的 postProcessAfterInitialization() 方法。 这个方法传入 原始Bean，返回处理过的 Bean ，我们在这里就可以对 这个 Bean 偷梁换柱，换成 Proxy 对象。实现我们代理的目的。 在 ProxyCreater 中实现了这个方法： 12345678910@Overridepublic Object postProcessAfterInitialization(Object bean, String beanName) throws BeansException { if (bean != null) { Object cacheKey = getCacheKey(bean.getClass(), beanName); if (!this.earlyProxyReferences.contains(cacheKey)) { return wrapIfNecessary(bean, beanName, cacheKey); } } return bean;} 这个方法干了这些事情： 把这个 bean 匹配的AOP增强配置打包成 advisor 保存这个Bean的接口方法 根据接口方法和配置决定使用 JDK Proxy 代理生成器（JdkDynamicAopProxy） 还是 CGLIB 代理生成器（ObjenesisCglibAopProxy） 来生成代理对象，一般情况下： 如果被代理的目标类实现了一个或多个自定义的接口，那么就会使用 JDK 动态代理 如果没有实现任何接口，会使用 CGLIB 实现代理。 生成代理对象后，把这个代理对象替换掉原来的 Bean 简单讲一下创建 JDK Proxy 代理，CGLIB类似，但是操纵比较复杂。Proxy 使用方法见 Java 动态代理机制 （一） JDK Proxy 详解JdkDynamicAopProxy -&gt; getProxy1234567891011public Object getProxy(ClassLoader classLoader) { if (logger.isDebugEnabled()) { logger.debug(\"Creating JDK dynamic proxy: target source is \" + this.advised.getTargetSource()); } Class&lt;?&gt;[] proxiedInterfaces = AopProxyUtils.completeProxiedInterfaces(this.advised, true); findDefinedEqualsAndHashCodeMethods(proxiedInterfaces); // 获取这个Bean的所有接口，调用 JDK 的 Proxy 生成 Proxy // 第三个是 InvocationHandler，代理类实现了 InvocationHandler 接口，有 invoke 方法 return Proxy.newProxyInstance(classLoader, proxiedInterfaces, this);} 当我们调用 被 Proxy 代理的类的时候，都会调用到 JdkDynamicAopProxy 的 invoke 方法，invoke 方法 在我们原方法的周围做一些增强（从advisor中获取我们写好的增强函数）。剩下的就交给 JDK 来处理了。 参考资料Spring AOP 源码解析Spring AOP 使用介绍，从前世到今生What is the difference between Advisor and Aspect in AOP?","link":"/2018/07/30/yuque/spring-aop/"},{"title":"Spring MVC 用法备忘和原理简析","text":"概述Spring MVC 的 正式名称叫做 Spring Web MVC ，SpringMVC 本质上是一个 Servlet 接口的一个实现，需要在 Servlet 配置文件，一般是 web.xml 中配置。它的核心是 DispatcherServlet，它一方面实现了 Servlet 接口，一方面依赖 Spring 进行 Bean 的寻找，处理请求，处理错误等等。 本文没有什么干货，以转载为主，主要是一些用法备忘。用的时候再查文档或者找一些最佳实践。 使用免XML配置本文都是直接使用 Spring-Boot 中的 SpringMVC 进行讲解 我这里是讲一下 Servlet 3.0+之后的 免XML配置的方法， 这也是 Spring-boot中为什么不用 XML 就可以配置的原因。在 Servlet3.0+ 容器中（Tomcat7.0+），会自动寻找实现了 WebApplicationInitializer 接口的类，对容器的初始化配置。 最简单的配置类如下：123456789101112131415public class MyWebApplicationInitializer implements WebApplicationInitializer { @Override public void onStartup(ServletContext servletCxt) { // Load Spring web application configuration （在这里加载Spring） AnnotationConfigWebApplicationContext ac = new AnnotationConfigWebApplicationContext(); // Create and register the DispatcherServlet DispatcherServlet servlet = new DispatcherServlet(ac); ServletRegistration.Dynamic registration = servletCxt.addServlet(\"app\", servlet); registration.setLoadOnStartup(1); registration.addMapping(\"/app/*\"); }} 当然，如果是实际使用，请使用 Spring-Boot ，放弃传统的复杂 XML 配置 SSM 吧。 SpringMVC几种使用方式常用的到一些注解：类级：@RestController：写在类上，自动给每个添加 @ResponseBody@SessionAttributes：写在类上，规定一个共用的 Seesion 对象名 方法级：@ModelAttribute: 如果写在方法上面，会在每一个 Controller 执行前先执行，并且作为一个公共对象给各个方法传入。@GetMapping: 处理 get 请求，还有 Post Put Delete ，可以在这里定义 解析 URI 的参数@ResponseBody：返回值直接输出到返回值的Body中，如果返回值是类，会被 Spring 寻找合适的 Converter 转换成文本，一般会转成 Json 参数级：@RequestParam: 解析 url 问号后面的参数，如果是用类接收，Spring会寻找合适的 Converter 转成你的目标类，否则是文本。@SessionAttribute：把 Seesion 里面的对象传入@CookieValue : 把 Cookies 里面的对象传入@PathVariable()：解析 path 参数 （uri）@RequestBody: 输入的 RequestBody，如果是用类接收，Spring会寻找合适的 Converter 转成你的目标类，否则是文本。@RequestAttribute ：从已存在的对象（由ModelAttribute创建、拦截器插入的）获取对象@ModelAttribute:如果把 ModelAttribute 写在参数上面，使用时它会 首先查询 @ModelAttribute域（方法上面的） 有无绑定的该对象，若没有则查询@SessionAttributes 域上是否绑定了该对象，若没有则将URI中或者从URL参数的值按对应的名称绑定到该对象的各属性上。 RESTFul12345678910111213141516171819202122232425262728293031@RestControllerpublic class CategoryController { @Autowired CategoryDAO categoryDAO; @GetMapping(\"/category\") public List&lt;Category&gt; listCategory(@RequestParam(value = \"start\", defaultValue = \"0\") int start, @RequestParam(value = \"size\", defaultValue = \"5\") int size){ return new ArrayList&lt;Category&gt;(); } @GetMapping(\"/category/{id}\") public Category getCategory(@PathVariable(\"id\") int id) { return new Category(); } @PutMapping(\"/category\") public void addCategory(@RequestBody Category category) throws Exception { System.out.println(\"springMVC接受到浏览器以JSON格式提交的数据：\"+category); } @PostMapping(\"/category/{id}\") public String updateCategory(@ModelAttribute Category c) throws Exception { return \"done\"; } @DeleteMapping(\"/category/{id}\") public String deleteCategory(@ModelAttribute Category c) throws Exception { return \"done\"; }} 传统模版渲染的写法Conroller控制的数据其实都是 Model，最后都会转成 ModelAndView ，接着 Spring 会找到 Template 文件把 model 插进去，这里展示几种不同的写法1234567891011121314151617181920212223242526@Controllerpublic class IndexController { // 为每一个 Controller 都执行一次这个，创建一个公共对象 @ModelAttribute public Account addAccount(@RequestParam String number) { return accountManager.findAccount(number); } @GetMapping(\"/index1\") public String index1(Model model ) { // 这里也可以是 ModelMap ，差不多 model.addAttribute(\"result\", \"后台返回index1\"); return \"result\"; // 根据配置找到 /template/result.xxx 进行渲染 } @GetMapping(\"/index2\") public ModelAndView index2() { ModelAndView mv = new ModelAndView(\"result\"); mv.addObject(\"result\", \"后台返回index2\"); return mv; } // 跳转的写法 @PostMapping(\"/files/{path}\") public String upload(...) { // ... return \"redirect:files/{path}\"; }} 结合自动 Conver 获取 Seesion 和 Cookies 对象读取 Seesion,Cookies 自动转成对象12345678910111213141516171819202122232425262728293031@Controller@SessionAttributes(\"pet\") // 这种写法可以在不同页面中传递值public class EditPetForm { @GettMapping(\"redirectTest\") public String redirectTest(Model model){ model.addAttribute(\"pet\",new Pet()); return \"redirect:indexView\"; } @GetMapping(\"indexView\") public String handle(@ModelAttribute Pet pet, BindingResult errors, SessionStatus status) { if (errors.hasErrors) { // 如果有错误会传到 errors 里面 // ... } System.out.println(pet); status.setComplete();// 删掉 Seesion // ... } } // 或者直接这么写，读别的地方写入的 Seesion，如果要控制 Seesion 则 入参 为 HttpSession @RequestMapping(\"/demo1\") public String handle(@SessionAttribute(\"user\") User user) { // 括号可选 // ... } // 获取 Cookies 值 @GetMapping(\"/demo2\") public void handle(@CookieValue(\"JSESSIONID\") String cookie) { //... }} 错误处理123456789101112@Controllerpublic class SimpleController { @ExceptionHandler public String handle(IOException ex) { // ... } @ExceptionHandler({FileSystemException.class, RemoteException.class}) public ResponseEntity&lt;String&gt; handle(IOException ex) { // ... }} 验证12345678910111213141516171819202122232425262728293031public class PersonForm { @NotNull @Size(min=2, max=30) private String name; @NotNull @Min(18) private Integer age; public String toString() { return \"Person(Name: \" + this.name + \", Age: \" + this.age + \")\"; }}@Controllerpublic class WebController { @GetMapping(\"/\") public String showForm(PersonForm personForm) { return \"form\"; } @PostMapping(\"/\") public String checkPersonInfo(@Valid PersonForm personForm, BindingResult bindingResult) { if (bindingResult.hasErrors()) { return \"form\"; } return \"redirect:/results\"; }} 自定义Converter如果传入或者返回的值应该是 String，但是你却用一个对象来对应，这个时候就需要 Covert。默认情况下 ，返回值是 String （ResponseBody），传对象会自动转成 Json。 例如1234567public class Employee { private long id; private double salary; // standard constructors, getters, setters} 现在你想传入一个值做参数：?data=1,50000.00 可以自动转成上面的对象：12345@GetMapping(\"/string-to-employee\")public ResponseEntity&lt;Object&gt; getStringToEmployee( @RequestParam(\"data\") Employee employee) { return ResponseEntity.ok(employee);} 在 Springboot 中，你只需要添加这样一个对象，Spring就会自动转换：12345678910public class String2EmplyeeConverter implements Converter&lt;String, Employee&gt; { @Override public Employee convert(String s) { String[] data = s.split(\",\"); return new Employee( Long.parseLong(data[0]), Double.parseDouble(data[1])); }} 上面主要是备查，其他可查官方文档： Method Arguments Return Values 原理SpringMVC 流程图MVC其实就是把控制器 Controller 和视图View 分开，并且用 Model 储存实际的数据，在不同部分中流转。 收到HTTP请求后，DispatcherServlet会查询HandlerMapping以调用相应的Controller。 Controller 接受请求并根据使用的GET或POST等方法调用适当的服务方法。服务方法将基于定义的业务逻辑设置Model 数据。最后 Controller 将 View 名称、Model 返回给 DispatcherServlet。 DispatcherServlet把视图名称发给 ViewResolver，返回一个已经写好的视图（JSP文件或者其他模版文件） DispatcherServlet 把 Model 和 View 结合，返回给用户 拦截器流程1234567public interface HandlerInterceptor { boolean preHandle(HttpServletRequest request, HttpServletResponse response, Object handler) throws Exception; void postHandle(HttpServletRequest request, HttpServletResponse response, Object handler, ModelAndView modelAndView) throws Exception; void afterCompletion(HttpServletRequest request, HttpServletResponse response, Object handler, Exception ex) throws Exception;} 下面的HandlerAdapter 会调用相应的 Controller 方法 DispatcherServlet 中的代码节选：1234567891011121314151617181920212223242526272829303132333435//doDispatch方法//1、处理器拦截器的预处理（正序执行）HandlerInterceptor[] interceptors = mappedHandler.getInterceptors();if (interceptors != null) { for (int i = 0; i &lt; interceptors.length; i++) { HandlerInterceptor interceptor = interceptors[i]; if (!interceptor.preHandle(processedRequest, response, mappedHandler.getHandler())) { //1.1、失败时触发afterCompletion的调用 triggerAfterCompletion(mappedHandler, interceptorIndex, processedRequest, response, null); return; } interceptorIndex = i;//1.2、记录当前预处理成功的索引}}//2、处理器适配器调用我们的处理器mv = ha.handle(processedRequest, response, mappedHandler.getHandler());//当我们返回null或没有返回逻辑视图名时的默认视图名翻译（详解4.15.5 RequestToViewNameTranslator）if (mv != null &amp;&amp; !mv.hasView()) { mv.setViewName(getDefaultViewName(request));}//3、处理器拦截器的后处理（逆序）if (interceptors != null) {for (int i = interceptors.length - 1; i &gt;= 0; i--) { HandlerInterceptor interceptor = interceptors[i]; interceptor.postHandle(processedRequest, response, mappedHandler.getHandler(), mv);}}//4、视图的渲染if (mv != null &amp;&amp; !mv.wasCleared()) {render(mv, processedRequest, response); if (errorView) { WebUtils.clearErrorRequestAttributes(request);}//5、触发整个请求处理完毕回调方法afterCompletiontriggerAfterCompletion(mappedHandler, interceptorIndex, processedRequest, response, null); 12345678910111213141516171819// triggerAfterCompletion方法private void triggerAfterCompletion(HandlerExecutionChain mappedHandler, int interceptorIndex, HttpServletRequest request, HttpServletResponse response, Exception ex) throws Exception { // 5、触发整个请求处理完毕回调方法afterCompletion （逆序从1.2中的预处理成功的索引处的拦截器执行） if (mappedHandler != null) { HandlerInterceptor[] interceptors = mappedHandler.getInterceptors(); if (interceptors != null) { for (int i = interceptorIndex; i &gt;= 0; i--) { HandlerInterceptor interceptor = interceptors[i]; try { interceptor.afterCompletion(request, response, mappedHandler.getHandler(), ex); } catch (Throwable ex2) { logger.error(\"HandlerInterceptor.afterCompletion threw exception\", ex2); } } } } } 参考资料http://jinnianshilongnian.iteye.com/blog/1670856https://docs.spring.io/spring/docs/current/spring-framework-reference/web.html#spring-web","link":"/2018/08/07/yuque/spring-mvc/"},{"title":"SSH开发 - 配合Hibernate，通过泛型实现 BaseService ，抽象增改删查方法","text":"提要本文是 小小商城-SSH版的 细节详解系列 之一，项目 github：https://github.com/xenv/S-mall-ssh 本文代码大部分在 github 中 可以找到 在 SSH 开发中，Service层会有许多重复的，调用dao层的，增改删查的方法。对于重复的方法，我们可以用一个 BaseService 抽象出来。如图所示 普通Service的增改删查操作统一被抽象到 BaseService，普通Service继承BaseService后，只需实现少量独有的代码即可 这样，在 Action 层调用的时候，只需直接 categoryService.get(id) 就可以完成获取操作。 具体实现BaseService实现的难点在于，不知道 继承它的 普通 Service 对应的 实体类 是哪个，从而不能从 Hibernate 中 获取到相应的 数据库查询器，那么，怎么来解决这个问题呢？ 其实很简单，利用 泛型 ，子类在继承父类的时候实现泛型，初始化时，父类就可以读取到子类的泛型信息，从而实现了 子类 向 父类 传 数据。 父类根据子类携带的实体类信息，初始化 Hibernate 数据库查询器，子类在泛型继承的时候，就自动会调用子类指定的查询器，从而做到了抽象的效果。 在 小小商城 项目中，核心实现是这两个文件，Service4DAOImpl.java 和 BaseServiceImpl.java 下面，我会一步步教大家实现。 初始化时读取子类的泛型信息，创建 Hibernate 查询器1234567891011121314151617181920212223242526public class Service4DAOImpl&lt;P&gt; implements Service4DAO { protected DAO dao; protected Class clazz; public Service4DAOImpl() { ParameterizedType t = (ParameterizedType) (getClass().getGenericSuperclass()); if (t != null) { clazz = (Class) t.getActualTypeArguments()[0]; } } @Autowired public void setDao(DAO dao) { this.dao = dao; } public Criteria createCriteria() { return getSession().createCriteria(clazz).setResultTransformer(Criteria.DISTINCT_ROOT_ENTITY); } public Session getSession() { return dao.getSessionFactory().getCurrentSession(); }} 通过反射，子类继承该类时，会自动读取到 子类 携带的 实体类 ，然后我们将 hibernate 的 dao 自动注入进来，使用 createCriteria 就可以获取到相应的查询器 比如 ProductService 中 extends Service4DAOImpl ，我们就可以自动为其创建一个 Product 实体类的查询器了。 实现 BaseService ，抽象增改删查方法123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475public class BaseServiceImpl&lt;P&gt; extends Service4DAOImpl&lt;P&gt; implements BaseService { @Override public List list(Object... paramAndObjects) { Criteria c= createCriteria(); if(paramAndObjects.length%2 !=0){ return null; } for (int i=0;i&lt;paramAndObjects.length;i+=2){ if(paramAndObjects[i+1] == null){ c.add(Restrictions.isNull(paramAndObjects[i].toString())); continue; } if(paramAndObjects[i].equals(\"pagination\") &amp;&amp; paramAndObjects[i+1] instanceof Pagination) { c.setFirstResult(((Pagination)paramAndObjects[i+1]).getStart()); c.setMaxResults(((Pagination)paramAndObjects[i+1]).getCount()); continue; } if(paramAndObjects[i].equals(\"desc\") &amp;&amp; paramAndObjects[i+1] instanceof String){ c.addOrder(Order.desc(paramAndObjects[i+1].toString())); continue; } if(paramAndObjects[i].equals(\"asc\") &amp;&amp; paramAndObjects[i+1] instanceof String){ c.addOrder(Order.asc(paramAndObjects[i+1].toString())); continue; } if(paramAndObjects[i].equals(\"max\") &amp;&amp; NumberUtils.isDigits(paramAndObjects[i+1].toString())){ c.setMaxResults(Integer.valueOf(paramAndObjects[i+1].toString())); continue; } if(paramAndObjects[i].toString().contains(\"_like\") &amp;&amp; paramAndObjects[i+1] instanceof String){ String keyword = \"%\"+paramAndObjects[i+1].toString()+\"%\"; c.add(Restrictions.like(StringUtils.removeEnd(paramAndObjects[i].toString(),\"_like\"),keyword)); continue; } if(paramAndObjects[i].toString().contains(\"_gt\") &amp;&amp; NumberUtils.isDigits(paramAndObjects[i+1].toString())){ c.add(Restrictions.gt(StringUtils.removeEnd(paramAndObjects[i].toString(),\"_gt\"),paramAndObjects[i+1])); continue; } c.add(Restrictions.eq(paramAndObjects[i].toString(),paramAndObjects[i+1])); } c.addOrder(Order.desc(\"id\")); return c.list(); } @Override public Integer add(Object object) { Session session = getSession(); return (Integer)session.save(object); } @Override public void update(Object object) { Session session = getSession(); session.update(object); } @Override public void delete(Object object) { Session session = getSession(); try { //获取对象的setDeleteAt方法，插入一个时间 Method setDeleteAt = object.getClass().getMethod(\"setDeleteAt\",Date.class); setDeleteAt.invoke(object,new Date()); } catch (Exception e) { e.printStackTrace(); } session.update(object); }} 这里节选了项目里的文件的一部分代码，我们先看 update(Object object) ，在获取到 seesion 之后，我们直接调用 update 方法即可 在list方法中，我又对查询器进行进一步抽象，这样，我们在调用的时候，就可以顺带指定分页、顺序、搜索条件等，更加方便 普通Service 附带 上 泛型 信息这样，我们直接继承 BaseService 即可，无需再写任何代码 1234@Servicepublic class ProductServiceImpl extends BaseServiceImpl implements ProductService {} 在 Action 中调用那么，我们应该怎么调用这些 Service 呢，其实非常简单，在注入了 productService 之后，只需直接调用list方法即可 123456@Action(\"category\")public String category(){ fill(category); products = productService.list(\"category\",category,handleSort()[0],handleSort()[1],\"stock_gt\",0); return \"categoryPage\";} 那么，大功告成，Service 和 Action 都省下了 大量重复的代码。","link":"/2018/05/31/yuque/ssh-baseservice/"},{"title":"SSM开发 - 配合Mybatis，通过泛型实现 BaseService ，抽象增改删查方法","text":"提要 本文是 小小商城-SSM版的 细节详解系列 之一，项目 github：https://github.com/xenv/S-mall-ssm 本文代码大部分在 github 中 可以找到。 这篇文章其实和 SSH开发 | 配合Hibernate，通过泛型实现 BaseService ，抽象增改删查方法 大致一样，只是具体实现有一点区别。 在 SSM 开发中，Service层会有许多重复的，调用 mapper 层的，增改删查的方法。对于重复的方法，我们可以用一个 BaseService 抽象出来。如图所示： 普通 Service 的增改删查操作统一被抽象到 BaseService，普通Service继承BaseService后，只需实现少量独有的代码即可 这样，在 Controller 层调用的时候，只需直接 categoryService.get(id) 就可以完成获取操作。 具体实现 BaseService实现的难点在于，不知道 继承它的 普通 Service 对应的 mapper和example 是哪个，从而不能获取到相应的 mapper 类（mybatis动态代理过之后的）和example类，那么，怎么来解决这个问题呢？ 其实很简单，利用 泛型 ，子类在继承父类的时候实现泛型，初始化时，父类就可以读取到子类的泛型信息，从而实现了 子类 向 父类 传 数据。 父类根据子类携带的实体类信息，把mapper接口变成 mapper 实体，子类在泛型继承的时候，就自动会调用对应mapper，从而做到了抽象的效果。 在 小小商城 项目中，核心实现是这两个文件，BaseServiceImpl.java 和 Service4DAOImpl.java下面，我会一步步教大家实现。 1.初始化时读取子类的泛型信息，获取 mapper实体类 和 example 类 完整实现：Service4DAOImpl.java，如果不使用通用 mapper （SSM开发 | 实现 Mybatis 的通用 Mapper），则注入的是mybatis 的 SqlSessionTemplate而不是MapperFactory，注入SqlSessionTemplate需要配置 Spring文件 ，具体可参见前面的链接 1234567891011121314151617181920212223242526272829303132333435363738public class Service4DAOImpl&lt;M, E&gt; implements Service4DAO, InitializingBean { @Resource private MapperFactory mapperFactory; Mapper mapper; @Override /* 加载完 Service 后执行，获取对应 Service 和 Mapper */ public void afterPropertiesSet() throws Exception { mapper = getMapper(); } public Mapper getMapper() throws Exception { // 读取泛型第一个 M 的类型， ParameterizedType t = (ParameterizedType) (getClass().getGenericSuperclass()); Class mapperClass = null; if (t != null) { mapperClass = (Class) t.getActualTypeArguments()[0]; } return getMapper(mapperClass); } public Mapper getMapper(Class mapperInterface) throws Exception { return mapperFactory.getMapper(mapperInterface); } public BaseExample getExample() throws Exception { ParameterizedType t = (ParameterizedType) (getClass().getGenericSuperclass()); Class exampleClass = null; if (t != null) { exampleClass = (Class) t.getActualTypeArguments()[1]; } return (BaseExample) exampleClass.newInstance(); }} 这里其实暗藏一个大坑，就是 SqlSessionTemplate 的注入是在类初始化之后的，这样我们就没有办法使用在构造函数中使用 SqlSessionTemplate，正确的做法是 afterPropertiesSet(…)函数，Spring会自动在全部注入完成后调用这个函数，往这个Service里面注入对应的mapper。Example也是同理的。 2.实现 BaseService ，抽象增改删查方法123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687public class BaseServiceImpl&lt;M, E&gt; extends Service4DAOImpl&lt;M, E&gt; implements BaseService { @Override public List list(Object... paramAndObjects) throws Exception { BaseExample example = getExample(); Object criteria = example.createCriteria(); if (paramAndObjects.length % 2 != 0) { return null; } Pagination pagination = null; //默认按id排序 example.setOrderByClause(\"id desc\"); //默认对查询进行两次遍历查询 int depth = 2; for (int i = 0; i &lt; paramAndObjects.length; i += 2) { if (paramAndObjects[i].equals(\"order\") &amp;&amp; paramAndObjects[i + 1] instanceof String) { example.setOrderByClause(paramAndObjects[i + 1].toString()); continue; } if (paramAndObjects[i].equals(\"depth\") &amp;&amp; paramAndObjects[i + 1] instanceof Integer) { depth = (Integer) paramAndObjects[i + 1]; continue; } if (paramAndObjects[i].toString().contains(\"_like\") &amp;&amp; paramAndObjects[i + 1] instanceof String) { String column = StringUtils.replace(paramAndObjects[i].toString(), \"_like\", \"\"); criteria.getClass() .getMethod(\"and\" + StringUtils.capitalize(column) + \"Like\", String.class) .invoke(criteria, \"%\" + paramAndObjects[i + 1].toString() + \"%\"); continue; } if (paramAndObjects[i].toString().contains(\"_gt\") &amp;&amp; paramAndObjects[i + 1] instanceof Integer) { String column = StringUtils.replace(paramAndObjects[i].toString(), \"_gt\", \"\"); criteria.getClass() .getMethod(\"and\" + StringUtils.capitalize(column) + \"GreaterThan\", Integer.class) .invoke(criteria, paramAndObjects[i + 1]); continue; } if (paramAndObjects[i].equals(\"pagination\") &amp;&amp; paramAndObjects[i + 1] instanceof Pagination) { pagination = (Pagination) paramAndObjects[i + 1]; continue; } criteria.getClass() .getMethod(\"and\" + StringUtils.capitalize(paramAndObjects[i].toString()) + \"EqualTo\" , paramAndObjects[i + 1].getClass()) .invoke(criteria, paramAndObjects[i + 1]); } List list; if (pagination != null) { PageHelper.offsetPage(pagination.getStart(), pagination.getCount()); list = mapper.selectByExample(example, depth); pagination.setTotal((int) new PageInfo&lt;&gt;(list).getTotal()); } else { list = mapper.selectByExample(example, depth); } return list; } @Override public Integer add(BasePOJO object) throws Exception { return mapper.insert(object); } @Override public void update(BasePOJO object) throws Exception { mapper.updateByPrimaryKey(object); } @Override public BasePOJO get(int id) throws Exception { BasePOJO object = (BasePOJO) mapper.selectByPrimaryKey(id); if (object == null) { throw new NoSuchObjectException(\"访问的id不存在或已经被删除\"); } return object; } /** * @see BaseService */ @Override public void delete(BasePOJO object) throws Exception { object.setDeleteAt(new Date()); mapper.updateByPrimaryKey(object); }} 这里节选了项目里的文件的一部分代码，我们先看 update(Object object) ，我们直接调用 mapper 的 update 方法即可 在list方法中，我又对example的使用进行进一步抽象，这样，我们在调用的时候，就可以顺带指定分页、顺序、搜索条件等，更加方便 3.普通Service 附带 上 泛型 信息，继承 BaseService 以ProductService为例： 1234@Servicepublic class ProductServiceImpl extends BaseServiceImpl&lt;ProductMapper,ProductExample&gt; implements ProductService {} 无需再写任何代码，只需要加上泛型信息即可获取完整的BaseService的所有功能。 4. 在 Controller 中调用例如，注入ProductService之后，直接可以调用 BaseService 的 list 方法 1productService.list(\"cid\",category.getId(),\"order\",handleSort(sort),\"stock_gt\",0); OK，大功告成。","link":"/2018/05/31/yuque/ssm-baseservice/"},{"title":"一步一步查看 HashMap 源码","text":"概览本文使用 JDK1.8,我们先借助IDE对HashMap储存key-value的结构有个大致的了解先生成一个有100个数据的map，key是我自定义的对象，value是一个随机 Integer，然后用 IDE 透视： 可以看到，最主要的是table，和一些设置的数值。map最核心的结构是 table，是一个node的数组，node里面存着 key和value，而node本身是一个链表。或者是一个红黑树的节点 TreeNode。 我们用图直观的看一下： 这个样例的map的生成方法在扩展5，读完本文，你或许也可以做一个高度碰撞的HashMap。 构造函数我们常用的 HashMap 构造方法12345// 无参构造方法HashMap&lt;String, String&gt; map1 = new HashMap&lt;String, String&gt;();// 含参数构造方法HashMap&lt;String, String&gt; map2 = new HashMap&lt;String, String&gt;(16);HashMap&lt;String, String&gt; map3 = new HashMap&lt;String, String&gt;(16,0.75F); 查看源代码12345678910111213141516171819202122232425262728293031323334// HashMap 类定义public class HashMap&lt;K,V&gt; extends AbstractMap&lt;K,V&gt; implements Map&lt;K,V&gt;, Cloneable, Serializable// HashMap 构造函数public HashMap() { this.loadFactor = DEFAULT_LOAD_FACTOR; // all other fields defaulted // note: 设置 loadFactor 为 0.75 ，没啥好说的}// HashMap 含参构造函数 (int)public HashMap(int initialCapacity) { this(initialCapacity, DEFAULT_LOAD_FACTOR); // note: 执行下面一个函数，附带的 第二个参数 为 0.75}// HashMap 含参构造函数 (int, float)public HashMap(int initialCapacity, float loadFactor) { if (initialCapacity &lt; 0) throw new IllegalArgumentException(\"Illegal initial capacity: \" + initialCapacity); // note: 良好的检查，负数第一时间抛出错误 if (initialCapacity &gt; MAXIMUM_CAPACITY) initialCapacity = MAXIMUM_CAPACITY; // note: 防止超过最大容量，最大容量值为 2^30 if (loadFactor &lt;= 0 || Float.isNaN(loadFactor)) throw new IllegalArgumentException(\"Illegal load factor: \" + loadFactor); // note: 检查 loadFactor 大于0，且不为 NaN this.loadFactor = loadFactor; this.threshold = tableSizeFor(initialCapacity); // note:调用了 tableSizeFor(initialCapacity) ， // 根据 initialCapacity 计算 threshold} 用到了几个变量，下面提到可以再回来找 K key的泛型类型 V value的泛型类型 float loadFactor 负载因子，默认是0.75 int initialCapacity 初始容量，用来计算 threshold int threshold 扩容门槛，默认是0 如果 HashMap 内数据超过 threshold * loadFactor 则会进行扩容操作。 无参数的构造方法比较平常，构造函数为其设置了 loadFactor ，而另外两个构造函数则设置了 initialCapacity 和 自定的 loadFactor。当传入 initialCapacity 之后，通过一个函数，我们最终计算出最重要的 threshold 属性。来看下这个函数，主要是通过位运算，让 threshold 始终是 2 的 平方数（方便扩容时重新落位） 123456789101112/** * Returns a power of two size for the given target capacity. */static final int tableSizeFor(int cap) { int n = cap - 1; n |= n &gt;&gt;&gt; 1; n |= n &gt;&gt;&gt; 2; n |= n &gt;&gt;&gt; 4; n |= n &gt;&gt;&gt; 8; n |= n &gt;&gt;&gt; 16; return (n &lt; 0) ? 1 : (n &gt;= MAXIMUM_CAPACITY) ? MAXIMUM_CAPACITY : n + 1;} 这里有个技巧，如果 HashMap 大小已知，则建议预设好threshold和loadFactor。防止map多次扩容（默认为0）。如现有100个数据，为防止扩容，则先计算扩容临界值 100/loadFactor(默认0.75) = 133，则 initialCapacity 应设置为 2 ^ 8 = 256 put()方法平时用法1map.put(\"test\",\"test\"); debug之，note里面如果不知道变量是什么，可以查看代码下方的变量表123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384public V put(K key, V value) { return putVal(hash(key), key, value, false, true);}// note：这里先执行了 hash() 方法static final int hash(Object key) { int h; return (key == null) ? 0 : (h = key.hashCode()) ^ (h &gt;&gt;&gt; 16); // 一般情况，使用 对象的 HashCode 计算 // 算法是 hash = hashcode ^ (hashcode &gt;&gt;&gt; 16)}// 返回第一个方法，执行 putVal()方法// 返回：如果被替换，返回旧值。如果未被替换，返回nullfinal V putVal(int hash, K key, V value, boolean onlyIfAbsent, boolean evict) { // 特别注意 hash = hash(key.hashCode)，并非原来的 hashCode Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; p; int n, i; if ((tab = table) == null || (n = tab.length) == 0) n = (tab = resize()).length; // 检查table有无初始化，第一次运行会到这里，进行 resize() 操作 // 这个操作后面会讲，这里这用来初始化 table 数组 if ((p = tab[i = (n - 1) &amp; hash]) == null) tab[i] = newNode(hash, key, value, null); // 用i = (n - 1) &amp; hash 计算 node 应该放在哪个槽位 // 这是一种对 hash 取余数的方法，取的结果会分布在 table 的长度之内 // 如果这个地方是 null // 那么，把key,value包装成 node，存入table[i] else { // 如果这个地方原来已经有一个 node Node&lt;K,V&gt; e; K k; if (p.hash == hash &amp;&amp; // note: 先检查旧的新的node的hash是否相等 ((k = p.key) == key || (key != null &amp;&amp; key.equals(k)))) // note: 检查旧key和和key的hashcode是否相等 ，或者旧key和新key是 equal 的 e = p; // note: 直接用新的node替换掉旧的node，跳转到 if (e != null) else if (p instanceof TreeNode) e = ((TreeNode&lt;K,V&gt;)p).putTreeVal(this, tab, hash, key, value); // note: 如果旧的note已经升级为 TreeNode ，那么用红黑树的方法来做 // 默认情况下，有多个node都在一个槽位的情况，是用链表的数据结构 // 但如果同一个槽位有超过8个node，则会升级为红黑树 else { // 这是默认情况的分支，有多个 node 都在同一个槽位，但是 hashcode 不相同 for (int binCount = 0; ; ++binCount) { // 写一个死循环 if ((e = p.next) == null) { // 一直到达 p.next 为 null p.next = newNode(hash, key, value, null); // 插入一个新 node if (binCount &gt;= TREEIFY_THRESHOLD - 1) // -1 for 1st treeifyBin(tab, hash); // 如果超过红黑树转换阈值，则转换为红黑树 break; } // 如果多个 node 的链表中，有一个 node 是和新node的key是一样的 // 结束循环，跳转到下面 if (e != null) if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) break; // p = p.next 遍历链表 p = e; } } if (e != null) { // existing mapping for key // 从上面跳转而来，判断是否要用新值替换旧值 V oldValue = e.value; if (!onlyIfAbsent || oldValue == null) // 用新值替换掉旧值，if判断可以设置不替换 e.value = value; // 钩子，没啥用 afterNodeAccess(e); return oldValue; } } ++modCount; if (++size &gt; threshold) // 判断是否需要扩容 resize(); // 钩子，没啥用 afterNodeInsertion(evict); return null; } 这里用到了一些变量 key put方法的传入 key 值 value put方法传入的 value 值 hashcode 对象的hashcode hash 对hashcode进行了二次计算，缩小了hashcode的大小 hash方法的意义在于，使得hashcode更加均匀，使hash值的位值在高低位上尽量分布均匀 Node&lt;K,V&gt; implements Map.Entry&lt;K,V&gt; static class Node&lt;K,V&gt; implements Map.Entry&lt;K,V&gt; { final int hash; final K key; V value; Node&lt;K,V&gt; next; Node(int hash, K key, V value, Node&lt;K,V&gt; next) { this.hash = hash; this.key = key; this.value = value; this.next = next; } key/value结构将被包装成Node这个数据结构 Node&lt;K,V&gt;[] table 存放数据的Node的数组 hash和槽位的算法：高16bit不变，低16bit和高16bit做了一个异或，可以在资源消耗比较低的情况下，打乱一下 hash，让计算出来的槽位下标更加均匀。通过hashCode()的高16位异或低16位实现的：(h = k.hashCode()) ^ (h &gt;&gt;&gt; 16)，主要是从速度、功效、质量来考虑的，这么做可以在bucket的n比较小的时候，也能保证考虑到高低bit都参与到hash的计算中，同时不会有太大的开销 get()方法平时用法 1map.get(\"test\"); 源码1234567891011121314151617181920212223242526272829public V get(Object key) { Node&lt;K,V&gt; e; return (e = getNode(hash(key), key)) == null ? null : e.value; // 计算 hash，调用 getNode 方法取出 node，返回 node.value}final Node&lt;K,V&gt; getNode(int hash, Object key) { Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; first, e; int n; K k; if ((tab = table) != null &amp;&amp; (n = tab.length) &gt; 0 &amp;&amp; (first = tab[(n - 1) &amp; hash]) != null) { // 获取到hash对应槽位的node if (first.hash == hash &amp;&amp; // always check first node ((k = first.key) == key || (key != null &amp;&amp; key.equals(k)))) // 检查 hashcode 是否相同，相同返回 这个 node，不相同继续遍历链表 return first; if ((e = first.next) != null) { // 判断红黑树的情况 if (first instanceof TreeNode) return ((TreeNode&lt;K,V&gt;)first).getTreeNode(hash, key); // 遍历链表，取出hashcode相同的node do { if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) return e; } while ((e = e.next) != null); } } return null; } resize()方法这是一个 HashMap 的私有方法，是非常重要的方法1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495final Node&lt;K,V&gt;[] resize() { Node&lt;K,V&gt;[] oldTab = table; // 暂存原来的 table int oldCap = (oldTab == null) ? 0 : oldTab.length; // 暂存原来的长度，为null说明是刚刚初始化，table还没有新建 int oldThr = threshold; // 暂存原来的threshold int newCap, newThr = 0; if (oldCap &gt; 0) { // 原来的 table 已经初始化走这里，是正常扩容 if (oldCap &gt;= MAXIMUM_CAPACITY) { // 超过最大值，不再扩容，碰撞的几率会增加 threshold = Integer.MAX_VALUE; return oldTab; } else if ((newCap = oldCap &lt;&lt; 1) &lt; MAXIMUM_CAPACITY &amp;&amp; oldCap &gt;= DEFAULT_INITIAL_CAPACITY) // 扩容两倍（原理见后） newThr = oldThr &lt;&lt; 1; // double threshold } else if (oldThr &gt; 0) // initial capacity was placed in threshold // 尚未初始化，但已经指定了初始大小 newCap = oldThr; else { // zero initial threshold signifies using defaults // 默认初始化，用默认值计算 threshold 和 newThr newCap = DEFAULT_INITIAL_CAPACITY; newThr = (int)(DEFAULT_LOAD_FACTOR * DEFAULT_INITIAL_CAPACITY); } // 如果没计算 newThr，现在再补算一次 if (newThr == 0) { float ft = (float)newCap * loadFactor; newThr = (newCap &lt; MAXIMUM_CAPACITY &amp;&amp; ft &lt; (float)MAXIMUM_CAPACITY ? (int)ft : Integer.MAX_VALUE); } threshold = newThr; @SuppressWarnings({\"rawtypes\",\"unchecked\"}) Node&lt;K,V&gt;[] newTab = (Node&lt;K,V&gt;[])new Node[newCap]; table = newTab; // 更新table，是一个空的table，容量是原来的两倍 if (oldTab != null) { // 如果原来有数据，走这里，遍历旧的table，拉出来重新插入 for (int j = 0; j &lt; oldCap; ++j) { Node&lt;K,V&gt; e; if ((e = oldTab[j]) != null) { // 原槽位存到e，并且不为空走这里 oldTab[j] = null; // 清空原槽位，等回收 if (e.next == null) // 如果这里不是链表（只有一个节点），直接重新落位 newTab[e.hash &amp; (newCap - 1)] = e; else if (e instanceof TreeNode) // 如果是红黑树，单独的分裂逻辑 ((TreeNode&lt;K,V&gt;)e).split(this, newTab, j, oldCap); else { // preserve order // 原来是链表 Node&lt;K,V&gt; loHead = null, loTail = null; Node&lt;K,V&gt; hiHead = null, hiTail = null; Node&lt;K,V&gt; next; do { next = e.next; // 遍历链表 if ((e.hash &amp; oldCap) == 0) { // 槽位未变，挂到loTail临时链表 if (loTail == null) loHead = e; else loTail.next = e; loTail = e; } else { // 槽位变成原槽位+oldCap // 挂到 hiTail 临时链表 if (hiTail == null) hiHead = e; else hiTail.next = e; hiTail = e; } } while ((e = next) != null); // 把原链表分裂成两个链表，然后分别扔到对应的槽位 if (loTail != null) { loTail.next = null; newTab[j] = loHead; } if (hiTail != null) { hiTail.next = null; newTab[j + oldCap] = hiHead; } } } } } // 如果原来没有数据，直接返回 return newTab; } 两倍扩容的算法因为是两倍扩容，n-1 永远 是 1 组成，所以重新计算槽位时，要么是在前面 加个 0，要么是前面加个1 如果是加0，那么槽位不动，如果是加1，那么等于移动了一个原容量 移动的过程相当于全部重新插入，所以是比较费时的 扩展扩展1：Hashcode的计算规则HashMap中，hash由hashcode计算得出，那么对象的hashcode如何计算呢？ Object类的hashCode.返回对象的内存地址经过处理后的结构，由于每个对象的内存地址都不一样，所以哈希码也不一样。这个是native方法，这个取决于JVM的设计，一般是某种地址的偏移。 String类的hashCode.根据String类包含的字符串的内容，根据一种特殊算法返回哈希码，只要字符串的内容相同，返回的哈希码也相同。 Integer等包装类，返回的哈希码就是Integer对象里所包含的那个整数的数值，例如Integer i1=new Integer(100),i1.hashCode的值就是100 。由此可见，2个一样大小的Integer对象，返回的哈希码也一样。 int，char这样的基础类，它们没有hashCode，如果需要存储时，将进行自动装箱操作，计算方法同上。 扩展2：HashMap与HashTable的主要区别他们的主要区别其实就是Table加了线程同步保护 HashTable线程更加安全，代价就是因为它粗暴的添加了同步锁，所以会有性能损失。 有更好的concurrentHashMap可以替代HashTable 扩展3：自定义对象作为 key 有什么要求必须要重写equals方法和hashCode方法，且放入map之后不要再修改对象重写hashCode方法，可以使用 Objects.hash(item1, item2, item3) 来多并一如果不重写，则相同内容的两个对象，如果内存地址不同，则会在map中有两个node最要命的是，你重新new一个自定义对象查询时(get())，如果内存地址和 map 内的 node 的内存地址不一致，将找不到你之前存的，内容一样的 node 扩展4：HashSet 和 HashMap有什么异同HashSet实际上用的是HashMap，HashSet的值是HashMap的key，HashSet在HashMap中的value是 new Object() 12345678910// HashSet add方法public boolean add(E e) { return map.put(e, PRESENT)==null;}// PRESENT定义为private static final Object PRESENT = new Object();// HashSet contains方法public boolean contains(Object o) { return map.containsKey(o);} 扩展5：生成一个高度碰撞的HashMap12345678910111213141516171819202122232425262728293031323334353637public class Main { public static void main(String[] args) { Random random = new Random(); Map&lt;EasyCollision, Integer&gt; map = Stream.generate(random::nextInt). limit(100).collect(Collectors.toMap(EasyCollision::new, Function.identity())); } static class EasyCollision{ private Integer hashSource; public EasyCollision(Integer hashSource) { this.hashSource = hashSource; } @Override public boolean equals(Object o) { if (o == null || getClass() != o.getClass()) return false; EasyCollision that = (EasyCollision) o; return Objects.equals(hashSource, that.hashSource); } @Override public int hashCode() { return hashSource % 15; } @Override public String toString() { return \"EasyCollision{\" + \"hashSource=\" + hashSource + '}'; } }} 参考资料Java HashMap工作原理及实现","link":"/2018/06/26/yuque/hashmap/"},{"title":"SSM开发 - 实现 Mybatis 的通用 Mapper","text":"提要 本文是 小小商城-SSM版的 细节详解系列 之一，项目 github：https://github.com/xenv/S-mall-ssm 本文代码大部分在 github 中 可以找到。 中小型项目使用 Mybatis 如何减少 mapper 的工作量？市面上已经有一款产品 ，叫”通用mapper”，但是我使用之后有点失望。一个是它侵入型极强，要改掉 mybatis 的 factory，数据库的名字和列名都要改成指定格式，错一个也不行。另外，还不支持关联查询，可谓是有点鸡肋了。于是，就有了我这么一个通用 mapper 的实现，可以让 Mybatis 像 Hibernate 一样使用。只要配置好自定义注解，用 mybatis-generator 生成好代码，就可以自动处理 各种关联查询（一对多、多对一自动插入），还提供接口修改遍历填充关联查询的深度，支持手写的扩展mappper接入到填充系统。 那么，这套系统到底是如何工作的呢？我做了一个示意图来说明 Category 表 下面的情况，其他表同理。 （mybatis-generator 隔离手写代码和机器代码请参考我写的文章：SSM开发 | 合理配置 mybatis-generator，隔离机器生成代码和额外增加代码） 当服务层调用的时候，通用 mapper 会先查询 服务器层指定的 CategoryMapper，从数据库拿到数据。然后通用 mapper 调用 MapperCore 对 拿到的Category进行一对多和多对一对象的填充。最后填充完的 category 对象将会返回给服务层。 一对多和多对一如何配置呢？这需要我们在 extension 类中 用自定义注解配置，然后机器生成的 Category 类 将继承 我们的 extension，因此 我们 最终拿到的 category 就是 有关联对象变量的 对象了。 那么，我们如何知道 一对多 多对一 的对象应该由哪个 mapper 来填充呢，那么我们就需要在 category 类上指定好 对应的 mapper （使用泛型继承）即可，怎么让它自动指定呢？对了，就是用 mybatis-generator 自定义插件。 在看具体实现之前，我假定您已经对 mybatis-generator 、自定义注解、反射有一定的了解。 具体实现1.创建 实体 extension 配置一对多、多对一信息 创建extension参见：：SSM开发 | 合理配置 mybatis-generator，隔离机器生成代码和额外增加代码 配置一对多、多对一信息使用自定义 注解，注解的定义在这里 ORMAnnotation 语法和 hibernate 差不多，临时变量不需要再使用注解，enum用了 (var=””)，取消了 OneToOne，因为本质上和 ManyToOne 是一样的，OneToOne还容易弄混。 配置好注解之后，效果是这样的： extension 2.定义 mybatis-generator 插件，让自动生成的 mapper 和 实体类 带上 泛型 信息，以供通用 mapper 读取 自定义 mybatis-generator 插件 参见我的文章：SSM开发 | 开发自定义插件，使 mybatis-generator 支持软删除 插件代码见：MapperExtendsPlugin.java POJOExtendsPlugin.java 之后用 mybatis-generator 生成出来的代码，就会是这样的 123undefinedpublic interface CategoryMapper extends BaseMapper&lt;Category, CategoryExample&gt; {} 12public class Category extends CategoryExtension implements POJOMapper&lt;CategoryMapper&gt; {} 这样，我们在填充时，读取这个类的时候，就可以通过反射，拿到 &lt;&gt; 中的内容，比如现在知道了一个 product 对象，里面要我们填充一个 Categorty 类，那么我们先来查 Category 类，知道对应的 Mapper 是 CategoryMapper，对应的 Example 是 CategoryEmaple，那么，我们就可以愉快的调用 CategoryMapper 拿到一个 category ，然后插回 product 即可。 3.开发通用 mapper ：静态代理+递归填充 我们先通过拿到 mybatis 自带的 sqlSessionTemplate ，需要在 applicationContext.xml 中 注册一下 123&lt;bean id=\"sqlSessionTemplate\" class=\"org.mybatis.spring.SqlSessionTemplate\"&gt; &lt;constructor-arg index=\"0\" ref=\"sqlSession\"/&gt;&lt;/bean&gt; 然后我们开发一个 MapperFactory 工厂类，用来在Service层获取我们的通用 mapper，并且从 SqlSessionTemplate 拿到 CateogoryMapper，塞进通用 mapper 里面，最后返回通用 mapper MapperFactory.java 1234567891011@Componentpublic class MapperFactory { @Resource private SqlSessionTemplate sqlSessionTemplate;public Mapper getMapper(Class mapperInterface) throws Exception { Mapper mapper = new Mapper(); mapper.setSqlSessionTemplate(sqlSessionTemplate); mapper.setMybatisMapper(mapperInterface); return mapper; }} 通用 mapper 里面其实比较简单，就是直接使用反射做通用具体mapper的静态代理，并且调用 mapperCore 中 的递归填充器 Mapper.java 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849public class Mapper extends Mapper4ORM { private int defaultTraversalDepth = 2; public Object selectByPrimaryKey(Integer id) throws Exception { return selectByPrimaryKey(id, defaultTraversalDepth); } public Object selectByPrimaryKey(Integer id, Integer depth) throws Exception { Object object = mapper.getClass().getMethod(\"selectByPrimaryKey\", Integer.class).invoke(mapper, id); fillOnReading(object, depth); return object; } public int insert(Object object) throws Exception { fillOnWriting(object); return (int) mapper.getClass().getMethod(\"insert\", object.getClass()).invoke(mapper, object); } public int insertSelective(Object object) throws Exception { fillOnWriting(object); return (int) mapper.getClass().getMethod(\"insertSelective\", Object.class).invoke(mapper, object); } public int updateByPrimaryKeySelective(Object object) throws Exception { fillOnWriting(object); return (int) mapper.getClass(). getMethod(\"updateByPrimaryKeySelective\", object.getClass()).invoke(mapper, object); } public int updateByPrimaryKey(Object object) throws Exception { fillOnWriting(object); return (int) mapper.getClass().getMethod(\"updateByPrimaryKey\", object.getClass()).invoke(mapper, object); } public List selectByExample(Object example) throws Exception { return selectByExample(example, defaultTraversalDepth); } public List selectByExample(Object example, int depth) throws Exception { List result = (List) mapper.getClass().getMethod(\"selectByExample\", example.getClass()).invoke(mapper, example); for (int i = 0; i &lt; result.size(); i++) { Object item = result.get(i); fillOnReading(item, depth); result.set(i, item); } return result; }} 最后，我们开发我们核心类，就是开发递归填充器，对一对多、多对一进行读取、处理、回填 Mapper4ORM.java 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283/** * 通用 Mapper | 核心，处理一对多，多对一的插入 */@SuppressWarnings(\"unchecked\")public class Mapper4ORM { Object mapper; private Class mapperInterface; private SqlSessionTemplate sqlSessionTemplate; void setSqlSessionTemplate(SqlSessionTemplate sqlSessionTemplate) { this.sqlSessionTemplate = sqlSessionTemplate; } void setMybatisMapper(Class mapperInterface) throws Exception { this.mapperInterface = mapperInterface; mapper = getMapper(mapperInterface); } public Object getMapper(Class mapperInterface) throws Exception { return sqlSessionTemplate.getMapper(mapperInterface); } public BaseExample getExample(Class mapperInterface) throws Exception { ParameterizedType t = (ParameterizedType) mapperInterface.getGenericInterfaces()[0]; Class exampleClass = (Class) t.getActualTypeArguments()[1]; return (BaseExample) exampleClass.newInstance(); } public Class getMapperInterfaceByPOJO(Class POJOClass) throws Exception { ParameterizedType t = (ParameterizedType) POJOClass.getGenericInterfaces()[0]; return (Class) t.getActualTypeArguments()[0]; } /** * 获取一个类里的，有指定annotation的，所有 Filed * * @param objectClass 一个类 * @param annotationClass 指定的 annotation * @return 所有的 Filed */ List&lt;Field&gt; getFieldsEquals(Class objectClass, Class annotationClass) { if (objectClass == null) { return null; } List&lt;Field&gt; fields = new ArrayList&lt;&gt;(); for (Class temp = objectClass; temp != Object.class; temp = temp.getSuperclass()) { fields.addAll(Arrays.asList(temp.getDeclaredFields())); } List&lt;Field&gt; result = new ArrayList&lt;&gt;(); for (Field field : fields) { if (field.getAnnotation(annotationClass) != null) result.add(field); } return result; } /** * 读取时，处理所有 多对一 的填充 * * @param object 被填充的对象 * @param depth 当前深度 * @throws Exception 反射异常 */ public void fillManyToOneOnReading(Object object, int depth) throws Exception { if (object == null) { return; } Class clazz = object.getClass(); // 获取所有 ManyToOne注解的Filed List&lt;Field&gt; result = getFieldsEquals(clazz, ManyToOne.class); for (Field field : result) { //获取外键的表名 String joinColumn = field.getAnnotation(JoinColumn.class).name(); //获取要填充对象的mapper Class targetMapperClass = getMapperInterfaceByPOJO(field.getType()); Object targetMapper = getMapper(targetMapperClass); //获取外键值 Integer joinColumnValue = (Integer) clazz. getMethod(\"get\" + StringUtils.capitalize(joinColumn)).invoke(object); if (joinColumnValue == null) { continue; } //配置查询器example BaseExample example = getExample(targetMapperClass); Object criteria = example.createCriteria(); // 配置criteria criteria.getClass().getMethod(\"andIdEqualTo\", Integer.class).invoke(criteria, joinColumnValue); //查询,获取结果列表 List targetResults = (List) targetMapper.getClass().getMethod(\"selectByExample\", example.getClass()). invoke(targetMapper, example); //判断是否为空 ，不为空插入 filed if (targetResults.size() &gt; 0) { Object targetResult = targetResults.get(0); fillOnReading(targetResult, depth - 1); clazz.getMethod(\"set\" + StringUtils.capitalize(field.getName()), targetResult.getClass()) .invoke(object, targetResult); } } } /** * 读取时，处理所有 一对多 的填充 * * @param object 被填充的对象 * @param depth 当前深度 * @throws Exception 反射异常 */ public void fillOneToManyOnReading(Object object, int depth) throws Exception { if (object == null) { return; } Class clazz = object.getClass(); // 获取所有 ManyToOne注解的Filed List&lt;Field&gt; result = getFieldsEquals(clazz, OneToMany.class); for (Field field : result) { //获取外键的表名 String joinColumn = field.getAnnotation(JoinColumn.class).name(); //得到其Generic的类型 Type genericType = field.getGenericType(); ParameterizedType pt = (ParameterizedType) genericType; //得到List泛型里的目标类型对象 Class targetClass = (Class) pt.getActualTypeArguments()[0]; //获取要填充对象的mapper Class targetMapperClass = getMapperInterfaceByPOJO(targetClass); Object targetMapper = getMapper(targetMapperClass); //获取外键值 Integer joinColumnValue = (Integer) clazz. getMethod(\"getId\").invoke(object); //配置查询器example BaseExample example = getExample(targetMapperClass); Object criteria = example.createCriteria(); // 配置criteria criteria.getClass().getMethod(\"and\" + StringUtils.capitalize(joinColumn) + \"EqualTo\", Integer.class).invoke(criteria, joinColumnValue); //查询,获取结果列表 List targetResults = (List) targetMapper.getClass().getMethod(\"selectByExample\", example.getClass()). invoke(targetMapper, example); for (int i = 0; i &lt; targetResults.size(); i++) { Object item = targetResults.get(i); fillOnReading(item, depth - 1); targetResults.set(i, item); } //插入 filed clazz.getMethod(\"set\" + StringUtils.capitalize(field.getName()), List.class) .invoke(object, targetResults); } } /** * 读取时，处理所有 Enum 的填充 * * @param object 被填充的对象 * @throws Exception 反射异常 */ public void fillEnumOnReading(Object object) throws Exception { if (object == null) { return; } Class clazz = object.getClass(); // 获取所有 ManyToOne注解的Filed List&lt;Field&gt; result = getFieldsEquals(clazz, Enumerated.class); for (Field field : result) { //获取Enum对应的，String类型的变量名 String varName = field.getAnnotation(Enumerated.class).var(); //获取值 String enumString = (String) clazz. getMethod(\"get\" + StringUtils.capitalize(varName)).invoke(object); // 转成Enum，插回 filed Enum resultObj = Enum.valueOf((Class&lt;Enum&gt;) field.getType(), enumString); clazz.getMethod(\"set\" + StringUtils.capitalize(field.getName()), resultObj.getClass()) .invoke(object, resultObj); } } /** * 写入时，处理所有 Enum 的填充 * * @param object 被填充的对象 * @throws Exception 反射异常 */ public void fillEnumOnWriting(Object object) throws Exception { if (object == null) { return; } Class clazz = object.getClass(); // 获取所有 ManyToOne注解的Filed List&lt;Field&gt; result = getFieldsEquals(clazz, Enumerated.class); for (Field field : result) { //获取Enum对应的，String类型的变量名 String varName = field.getAnnotation(Enumerated.class).var(); //获取 Enum Enum enumObj = (Enum) clazz. getMethod(\"get\" + StringUtils.capitalize(field.getName())).invoke(object); // 转成 String，插回 varName String enumString = enumObj.name(); clazz.getMethod(\"set\" + StringUtils.capitalize(varName), String.class) .invoke(object, enumString); } } /** * 写入时，处理所有 ManyToOne 的填充 * * @param object 被填充的对象 * @throws Exception 反射异常 */ public void fillManyToOneOnWriting(Object object) throws Exception { if (object == null) { return; } Class clazz = object.getClass(); // 获取所有 ManyToOne注解的Filed List&lt;Field&gt; result = getFieldsEquals(clazz, ManyToOne.class); for (Field field : result) { //获取One端的变量名 String columnName = field.getAnnotation(JoinColumn.class).name(); //获取One的对象 Object targetObj = clazz .getMethod(\"get\" + StringUtils.capitalize(field.getName())) .invoke(object); if (targetObj == null) { continue; } //获取 获取 id 值 int id = (int) targetObj.getClass(). getMethod(\"getId\").invoke(targetObj); // 插回 columnName clazz.getMethod(\"set\" + StringUtils.capitalize(columnName), Integer.class) .invoke(object, id); } } /** * 读取时填充数据，递归调用上面的方法 * @param object 对象 * @param depth 当前递归深度 * @throws Exception 反射异常 */ public void fillOnReading(Object object, int depth) throws Exception { if (object == null) { return; } if (depth &lt;= 0) { return; } // 处理 ManyToOne fillManyToOneOnReading(object, depth); // 处理 OneToMany fillOneToManyOnReading(object, depth); // 处理 Enumerated fillEnumOnReading(object); } /** * 写入时填充数据，递归调用上面的方法 * @param object 对象 * @throws Exception 反射异常 */ public void fillOnWriting(Object object) throws Exception { if (object == null) { return; } // 处理 Enumerated fillEnumOnWriting(object); // 处理 ManyToOne fillManyToOneOnWriting(object); }} 4.在service层调用12@Resource private MapperFactory mapperFactory; 拿到 mapperFactory ，如果要对CategoryMaper进行填充处理的话，就直接用mapperFactory.getMapper(mapperInterface);即可拿到对应的通用 mapper ，然后和 原来的 mybatis mapper 使用 方法一样。 后记 毫无疑问，这个通用 mapper 还很不完善，效率也比较低，现在的实现只相当于玩具的级别。而且市面上也已经有了一系列 jpa系统实现，这个通用mapper存在的意义也不是十分大。 但是，我们可以通过这个 mapper 理解到泛型、反射的一系列用法，递归的实操中的使用，还可以对mybatis-generator有了更深的理解 这个 mapper 也在我的 小小商城-ssm版中 完整运用了，为此我可以使用 mybatis 而不用写 一行 sql 代码。 时间仓促，涉及到的知识点也太多，文章非常简略，对新手也不是十分友好，在此表示歉意。如果想详细理解这个 通用 mapper ，可以到项目 github 中 查看全部源代码，或者发邮件、留言和我交流 （邮件地址在Github首页）。","link":"/2018/05/31/yuque/mybatis-general-mapper/"},{"title":"Java Stream 解析和使用技巧","text":"Stream简介Stream是一种为lambda设计的一种操作流水线。创建一个Stream之后，你可以添加你想要的多个中间操作到流水线中，然后使用终结操作，原始数据就会通过你设计的Stream流水线，输出给终结操作，然后输出数据。 所以，看本文之前，请确保你已经对 lambda 已经足够了解。lambda解析：https://yuque.com/page/luan.ma/lambda/ Stream的类型Stream有分普通流和数值流，之间没有继承关系，普通流用一个泛型表示流中的数据结构类型，如Stream数值流主要是避免重复的装箱拆箱，统一用原始数值类型（无法应用泛型指定类型），int long double，我们在做终结操作的时候需要统一装箱 .box() 转成普通流 Stream的生命周期创建流 -&gt; 中间操作 -&gt; 终结操作 Stream的特点 无存储。stream不是一种数据结构，它只是某种数据源的一个视图，数据源可以是一个数组，Java容器或I/O channel等。 为函数式编程而生。对stream的任何修改都不会修改背后的数据源，比如对stream执行过滤操作并不会删除被过滤的元素，而是会产生一个不包含被过滤元素的新stream。 惰式执行。stream上的操作（中间操作）并不会立即执行，只有等到用户真正需要结果的时候（终结操作）才会执行。 可消费性。stream只能被“消费”一次，一旦遍历过就会失效（终结操作就是消费操作），就像容器的迭代器那样，想要再次遍历必须重新生成。 区分中间操作和结束操作最简单的方法，就是看方法的返回值，返回值为stream的大都是中间操作，否则是结束操作。 创建流 从 Colletion .stream() .parallelStream() 从数组 Arrays.stream(T array) Stream.of() 从输入流 BufferedReader.lines() 从目录树 Files.walk(Paths.get(“C:\\“)) 创建各种数值流 Random.ints() IntStream.of() IntStream.range() …Stream.***() 自己创建流（可创建无穷流） Stream.generate() 丢进一个类似迭代器的东西即可 Stream.iterate(0, n -&gt; n + 3).limit(10). forEach(x -&gt; System.out.print(x + “ “)); 创建一个自己迭代的流 中间操作 并行化 .parallel() 装箱操作 .boxed() 把数值流转回普通流，才能执行终结操作 转换操作 一对一普通转换 .map() 一对多转换 .flatMap() 本 质上是把每个对象转换成流，流会自动合并 123Stream&lt;List&lt;Integer&gt;&gt; stream = Stream.of(Arrays.asList(1,2), Arrays.asList(3, 4, 5));stream.flatMap(list -&gt; list.stream()) .forEach(i -&gt; System.out.println(i)); 3. 直接转成 数值流 .mapToInt .flatMapToInt 排序操作 .sorted 对每一个对象操作 .peek 保留前n项 .limit() 无穷流必须执行限流操作，否则将进入死循环 去掉前n项 .skip() 筛选操作 .filter() true留，false被删除 终结操作 终结操作后Stream将会被消费完成，不能再执行中间操作 转数组 .toArray() stream.toArray(String[]::new) 转 Collection/String .collect() forEach 逐一消费所有项目 无法提前结束循环，只能用return提前结束当前循环 两两结合操作 .reduce() .max .min .findFirst .findAny match 检查 allMatch：Stream 中全部元素符合传入的 predicate，返回 true anyMatch：Stream 中只要有一个元素符合传入的 predicate，返回 true noneMatch：Stream 中没有一个元素符合传入的 predicate，返回 true reduce操作reduce操作可以实现从一组元素中生成一个值，sum()、max()、min()、count()等都是reduce操作，将他们单独设为函数只是因为常用。reduce()的方法定义有三种重写形式： Optional&lt;T&gt; reduce(BinaryOperator&lt;T&gt; accumulator) T reduce(T identity, BinaryOperator&lt;T&gt; accumulator) &lt;U&gt; U reduce(U identity, BiFunction&lt;U,? super T,U&gt; accumulator, BinaryOperator&lt;U&gt; combiner) 虽然函数定义越来越长，但语义不曾改变，多的参数只是为了指明初始值（参数identity），或者是指定并行执行时多个部分结果的合并方式（参数combiner）。reduce()最常用的场景就是从一堆值中生成一个值。用这么复杂的函数去求一个最大或最小值，你是不是觉得设计者有病。其实不然，因为“大”和“小”或者“求和”有时会有不同的语义。而Optional是（一个）值的容器，可以避免null值的问题，下面会提到。 需求：从一组单词中找出最长的单词。这里“大”的含义就是“长”。 12345// 找出最长的单词Stream&lt;String&gt; stream = Stream.of(\"I\", \"love\", \"you\", \"too\");Optional&lt;String&gt; longest = stream.reduce((s1, s2) -&gt; s1.length()&gt;=s2.length() ? s1 : s2);//Optional&lt;String&gt; longest = stream.max((s1, s2) -&gt; s1.length()-s2.length());System.out.println(longest.get()); 需求：求出一组单词的长度之和。这是个“求和”操作，操作对象输入类型是String，而结果类型是Integer。 1234567// 求单词长度之和Stream&lt;String&gt; stream = Stream.of(\"I\", \"love\", \"you\", \"too\");Integer lengthSum = stream.reduce(0, // 初始值 // (1) (sum, str) -&gt; sum+str.length(), // 累加器 // (2) (a, b) -&gt; a+b); // 部分和拼接器，并行执行时才会用到 // (3)// int lengthSum = stream.mapToInt(str -&gt; str.length()).sum();System.out.println(lengthSum); Collect操作Collect是终结操作的一个函数，最为强大，不仅可以将流转化成各种数据结构，也可以再补充中间操作不能进行许多操作。 收集器（Collector）是为Stream.collect()方法量身打造的工具接口（类）。考虑一下将一个Stream转换成一个容器（或者Map）需要做哪些工作？我们至少需要两样东西： 目标容器是什么？是ArrayList还是HashSet，或者是个TreeMap。 新元素如何添加到容器中？是List.add()还是Map.put()。 如果并行的进行规约，还需要告诉collect() 3. 多个部分结果如何合并成一个。 结合以上分析，collect()方法定义为 R collect(Supplier supplier, BiConsumer&lt;R,? super T&gt; accumulator, BiConsumer&lt;R,R&gt; combiner)，三个参数依次对应上述三条分析。不过每次调用collect()都要传入这三个参数太麻烦，收集器Collector就是对这三个参数的简单封装,所以collect()的另一定义为&lt;R,A&gt; R collect(Collector&lt;? super T,A,R&gt; collector)。Collectors工具类可通过静态方法生成各种常用的Collector。 举例来说，如果要将Stream规约成List可以通过如下两种方式实现：1List&lt;String&gt; list = stream.collect(ArrayList::new, ArrayList::add, ArrayList::addAll);// 方式１ 常用的转 Collection / String，Collectors为辅助类 转list stream.collect(Collectors.toList()); 转set stream.collect(Collectors.toSet()); 转其他 stream.collect(Collectors.toCollection(Stack::new)); 转String stream.collect(Collectors.joining()).toString(); 转 map 前面已经说过Stream背后依赖于某种数据源，数据源可以是数组、容器等，但不能是Map。反过来从Stream生成Map是可以的，但我们要想清楚Map的key和value分别代表什么，根本原因是我们要想清楚要干什么。通常在三种情况下collect()的结果会是Map： 使用Collectors.toMap()生成的收集器，用户需要指定如何生成Map的key和value。 使用Collectors.partitioningBy()生成的收集器，对元素进行二分区操作时用到。 使用Collectors.groupingBy()生成的收集器，对元素做group操作时用到。 情况1：使用toMap()生成的收集器，这种情况是最直接的，前面例子中已提到，这是和Collectors.toCollection()并列的方法。如下代码展示将学生列表转换成由&lt;学生，GPA&gt;组成的Map。。 12345// 使用toMap()统计学生GPAMap&lt;Student, Double&gt; studentToGPA = students.stream().collect(Collectors.toMap(Functions.identity(),// 如何生成key student -&gt; computeGPA(student)));// 如何生成value// Functions.identity() 是一个接口默认方法，return x-&gt;x，即它本身，在这里是 student -&gt; student 情况2：使用partitioningBy()生成的收集器，这种情况适用于将Stream中的元素依据某个二值逻辑（满足条件，或不满足）分成互补相交的两部分，比如男女性别、成绩及格与否等。下列代码展示将学生分成成绩及格或不及格的两部分。拉出来之后用 get(true) 和 get(false) 拉出去两个列表。 123// Partition students into passing and failingMap&lt;Boolean, List&lt;Student&gt;&gt; passingFailing = students.stream() .collect(Collectors.partitioningBy(s -&gt; s.getGrade() &gt;= PASS_THRESHOLD)); 情况3：使用groupingBy()生成的收集器，这是比较灵活的一种情况。跟SQL中的group by语句类似，这里的groupingBy()也是按照某个属性对数据进行分组，属性相同的元素会被对应到Map的同一个key上。下列代码展示将员工按照部门进行分组： 123// Group employees by departmentMap&lt;Department, List&lt;Employee&gt;&gt; byDept = employees.stream() .collect(Collectors.groupingBy(Employee::getDepartment)); 以上只是分组的最基本用法，有些时候仅仅分组是不够的。在SQL中使用group by是为了协助其他查询，比如1. 先将员工按照部门分组，2. 然后统计每个部门员工的人数。Java类库设计者也考虑到了这种情况，增强版的groupingBy()能够满足这种需求。增强版的groupingBy()允许我们对元素分组之后再执行某种运算，比如求和、计数、平均值、类型转换等。这种先将元素分组的收集器叫做上游收集器，之后执行其他运算的收集器叫做下游收集器(downstream Collector)。我们可以简单理解，下游收集器就是对map 的 values 做了一个 forEach 123456// 使用下游收集器统计每个部门的人数Map&lt;Department, Integer&gt; totalByDept = employees.stream() .collect(Collectors.groupingBy(Employee::getDepartment, // 变成 Map&lt;Department, List&lt;Employee&gt;&gt; // 对每一个 List&lt;Employee&gt; 执行 Collectors.counting()));// 下游收集器 上面代码的逻辑是不是越看越像SQL？高度非结构化。还有更狠的，下游收集器还可以包含更下游的收集器，这绝不是为了炫技而增加的把戏，而是实际场景需要。考虑将员工按照部门分组的场景，如果我们想得到每个员工的名字（字符串），而不是一个个Employee对象，可通过如下方式做到： 12345678910// 按照部门对员工分布组，并只保留员工的名字Map&lt;Department, List&lt;String&gt;&gt; byDept = employees.stream() .collect(Collectors.groupingBy(Employee::getDepartment, // Map&lt;Department, Stream&lt;Employee&gt;&gt; // 对每一个 Stream&lt;Employee&gt; ，执行 mapping，会遍历流中每一个数据 Collectors.mapping(Employee::getName,// 下游收集器 // 得到一个 Map&lt;Department, Stream&lt;String&gt;&gt; Collectors.toList())));// 更下游的收集器 // 得到 Map&lt;Department, List&lt;String&gt;&gt; // Map的key不用管，自动只处理 value 的 stream Optional容器 一般用法： 新建一个 可空 Optional，ifPresent非空则执行 xxx 操作Optional.ofNullable(text).ifPresent(System.out::println); 从reduce等stream终结函数返回 检查Optional是否为空，一般和三元符配合使用，可同时照顾到非空和空isPresent()?1:0; orElse() 用法，取值，如果为空，则为默认值（默认值马上获得，传入的是真实值）String name = Optional.ofNullable(nullName).orElse(“john”); orElseGet() 取值，如果为空，则为默认值，默认值为一个获取方法Optional.ofNullable(text).orElseGet(this::getMyDefault);当容器内的值为null时，orElse() 和 orElseGet() 完全相同，当容器内值不为 null 时，则 orElseGet() 不会执行相关的函数 .filter() 过滤，如果.filter()内容为真，则返回内容，如果为假，则容器内为空。支持链式操作 boolean is2017 = yearOptional.filter(y -&gt; y == 2017).isPresent(); .map() 转换，不用判断非空 int size = listOptional .map(List::size).orElse(0); .flatMap() 多层 Optional 自动拆开 Stream 底层实现Stream实际上是一个流水线（Pipelines），那么他的链式调用+惰性执行的原理是什么呢？ 所谓流水线，就是先装配，后启动，一次完成。而不是一步一步迭代实现，这样最大的弊端是没有办法应对复杂的数据结构。效率也十分低 我们举个例子 1234567List&lt;String&gt; test = Arrays.asList(&quot;liu&quot;,&quot;zhang&quot;,&quot;huang&quot;,&quot;chen&quot;,&quot;lix&quot;,&quot;fuc&quot;);Stream&lt;String&gt; t = test.stream();Stream&lt;String&gt; t2 = t.skip(2);Stream&lt;String&gt; t3 = t2.map(x -&gt; x.substring(2));Stream&lt;String&gt; t4 = t3.sorted();String t5 = t4.max(String::compareTo).orElse(&quot;&quot;); 这是一组流水线Stream拆开来生成多个Stream变量。我们知道，Stream实际上是一个接口，那么，我们调用了这些函数之后，到底返回了一个什么对象呢？我们直接用 IDE 告诉我们答案 可以看到，首先这里有一个双向链表的结构，每次中间操作，都会增加一个新的 AbstractPipeline，然后记录第一个 AbstractPipeline 和 上一个 AbstractPipeline，上一个 AbstractPipeline 也会记录当前新增的 AbstractPipeline。 而另一方面，根据增加的操作不同，也会有不同的 AbstractPipeline 子类，包括 ReferencePipeline, SliceOps, SortedOps, StatelessOp 等等，只是实现的层级不同，我们稍后在纠结这些。 并且，这些实现类内部会有一个 核心的逻辑方法opWrapSink(int flags, Sink&lt;P_OUT&gt; sink，会把逻辑打包成一个 Sink 对象，这个 Sink 对象还接收另外一个 Sink 对象作为构造函数参数。 我们拿 .filter() 举例，内置了一个函数会返回 Sink 对象，目前还是惰性执行，所以没有立刻生成： 12345678910111213141516171819202122@Override public final Stream&lt;P_OUT&gt; filter(Predicate&lt;? super P_OUT&gt; predicate) { Objects.requireNonNull(predicate); return new StatelessOp&lt;P_OUT, P_OUT&gt;(this, StreamShape.REFERENCE, StreamOpFlag.NOT_SIZED) { @Override Sink&lt;P_OUT&gt; opWrapSink(int flags, Sink&lt;P_OUT&gt; sink) { return new Sink.ChainedReference&lt;P_OUT, P_OUT&gt;(sink) { @Override public void begin(long size) { downstream.begin(-1); } @Override public void accept(P_OUT u) { if (predicate.test(u)) downstream.accept(u); } }; } }; } Sink对象源码，我们最关注的是构造函数，可以看到它又藏了另外一个 sink 12345678910111213141516171819202122static abstract class ChainedReference&lt;T, E_OUT&gt; implements Sink&lt;T&gt; { protected final Sink&lt;? super E_OUT&gt; downstream; public ChainedReference(Sink&lt;? super E_OUT&gt; downstream) { this.downstream = Objects.requireNonNull(downstream); } @Override public void begin(long size) { downstream.begin(size); } @Override public void end() { downstream.end(); } @Override public boolean cancellationRequested() { return downstream.cancellationRequested(); } } 当我们走到终结操作的时候，会先执行一个这样的操作： 12345678910final &lt;P_IN&gt; Sink&lt;P_IN&gt; wrapSink(Sink&lt;E_OUT&gt; sink) { Objects.requireNonNull(sink); // 检查非空 for ( @SuppressWarnings(\"rawtypes\") AbstractPipeline p=AbstractPipeline.this; p.depth &gt; 0; p=p.previousStage) { // 从后向前调用每个AbstractPipeline的opwrapSink，然后每个 Sink 藏着上一个 Sink sink = p.opWrapSink(p.previousStage.combinedFlags, sink); } return (Sink&lt;P_IN&gt;) sink;} 好了，千辛万苦，我们终于得到了这么一个 Sink，这个 Sink 保存了所有的中间流操作和最后一个 reduce 规约操作的所有操作对象。也就是说，我们的流水线建成了。 拿到这个 Sink 之后，我们就可以愉快的进行迭代了 12345678910111213// AbstractPipelie.copyInto()final &lt;P_IN&gt; void copyInto(Sink&lt;P_IN&gt; wrappedSink, Spliterator&lt;P_IN&gt; spliterator) { Objects.requireNonNull(wrappedSink); if (!StreamOpFlag.SHORT_CIRCUIT.isKnown(getStreamAndOpFlags())) { wrappedSink.begin(spliterator.getExactSizeIfKnown());// 调用遍历前钩子，通知数据大小 spliterator.forEachRemaining(wrappedSink);// 迭代器 wrappedSink.end();// 调用遍历后钩子 } else { copyIntoWithCancel(wrappedSink, spliterator); }} 遍历调用 Sink的begin() 钩子，主要是用来准备数据结构，每个Sink的begin都会递归调用下游的begin1234// SliceOpspublic void begin(long size) { downstream.begin(calcSize(size, skip, m));} 调用 forEachRemaining() 方法123456789101112131415161718192021// Spliteratorsif ((a = array).length &gt;= (hi = fence) &amp;&amp; (i = index) &gt;= 0 &amp;&amp; i &lt; (index = hi)) { do { action.accept((T)a[i]); } while (++i &lt; hi);}// 就是这么简单粗暴，把 Stream 里面的东西一个一个调用 Sink 里面的 accept 方法// 然后，这个东西又会调用下游的 accept// SliceOps@Overridepublic void accept(T t) { if (n == 0) { if (m &gt; 0) { m--; downstream.accept(t); } } else { n--; }}// 这里，我们可以看到，切割操作就是有的元素不往下传，就gg了，往下传就继续下面的 accept() 最后调用 end() 方法封口，同样是递归调用1234567891011121314151617181920212223242526272829// SotedOps()// Sort有他的特殊性，不能在 accept 的时候一个一个执行，只能在封口的时候，再排序public void end() { list.sort(comparator); // 排序 downstream.begin(list.size()); // 通知下游准备 if (!cancellationWasRequested) { // 下游Sink不包含短路操作 list.forEach(downstream::accept); // 把元素继续一个一个丢给下游 } else { for (T t : list) { //把元素一个一个拉出来 if (downstream.cancellationRequested()) break;// 每次都调用cancellationRequested()询问是否可以结束处理。 downstream.accept(t); //否则，把这个交给下游 } } downstream.end(); // 调用下游的 end()函数 list = null;}// 来看下它的其他两个操作，可以看到，他并没有调用下游操作，而是直接拦截了，等到 end 的时候再通知下游@Overridepublic void begin(long size) { ... // 创建一个存放排序元素的列表 list = (size &gt;= 0) ? new ArrayList&lt;T&gt;((int) size) : new ArrayList&lt;T&gt;();}@Overridepublic void accept(T t) { // Sorted的违规操作， list.add(t);// 1. 使用当前Sink包装动作处理t，只是简单的将元素添加到中间列表当中} 经过这些处理之后，会被丢进 reduce 操作 或者是 collect 操作收集 流中的数据。 关于并且流时候的情况，调用了 Fork/Join 框架，比较复杂，以后再更。 参考资料深入理解Java函数式编程和Streams API","link":"/2018/07/13/yuque/stream/"},{"title":"Spring 核心：Spring IOC 用法和原理解析","text":"本文主要讲解 Spring 的核心和最基本的功能： Spring IOC （对应的包主要是 Spring-context 和 Spring-Beans） Spring IOC 概述IOC(Inversion of Control) 控制反转，也叫 DI(Dependency injection) 依赖注入。是一种设计思想。不过我并不同意所谓反转的说法，因为没有谁规定什么方式就是“标准”的，如果我把IOC作为“标准”，IOC就是“标准”自身，何来反转？不过我行文也是沿用官方的说法，使用IOC描述这个技术 IOC其实是一种组装的思想，最简单理解 IOC 的方法，就是我们的组装电脑。 主板，硬盘，显卡，CPU厂商们先定义好一个个插口。 然后主板厂商就在他的主板上面预留位置。比如 A 插口是 留给硬盘的，B插口是留给 CPU的。注意，主板生产完成时，硬盘和CPU并没有在主板上，而是空的，不过主板已经写好好了给 CPU 和 硬盘 供电的 功能。 我们的工作就是根据主板的插口来找件，装配，而不是先买CPU、内存、硬盘再去选主板，这就是IOC ，主板需要插什么接口的，我们就去获得相关的零件，这样整个电脑就可以工作。 首先，我们必须要知道，没有 Spring ，我们照样可以做所谓的 IOC，就是 主物预留插口 -&gt; 按插口找件，组装。其实这在我们生活中随处可见。 那么，我们为什么要使用 Spring 呢，我们组装电脑，就要获得关于这个电脑的所有部件，比如主板、电源、内存等等，我们自己当然不可能凭空造出来，但是我们可以上商城购买，我们只需要关心接口对不对，而不用关心他是怎么生产的。那么，Spring 的角色就是一个商城。 我们可以把 Spring IOC 看成一个全产业链的商城，他会把产业链中的第一层原料开始，每一层都登记进入商城。在这个商城里面，我们可以买到任何层级的零件。之后，我们就可以自由的控制一切：如果我们是厂商，我们可以买到我们想要的零件。如果我们是消费者，想组装电脑，就可以买到主板，硬盘和CPU。如果我们有了机房，就可以直接买到若干个电脑。甚至，我们有一个国家，就可以在上面买到关于这个国家的一切。我们再不用关心东西是怎么来的，我们只管买即可。东西生产由其他人负责。而Spring IOC做的就是整个产业链从头到尾的组装，上架工作。 Spring IOC的好处也是众说纷纭，我也没有找到很有说服力的解释，姑且写一些在下面： 轻松实现面向接口编程，中心管理，按需取用，各个环节完全解耦，比如，网站环境和测试环境差异巨大，也可以轻松切换。 可以监听和控制所管理对象的生命周期，并且执行相关的操作 因为可以控制对象的生命周期，所以可以轻松通过 AOP 进行对象增强 轻松整合整个 Java 生态链，对于开发者来说，整合是轻松友好的。 Spring IOC 用法解析随着 SpringBoot 的潮流， 我们坚持只使用注解配置 Spring IOC SpringIOC使用例子maven 配置依赖12345&lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-context&lt;/artifactId&gt; &lt;version&gt;4.3.11.RELEASE&lt;/version&gt;&lt;/dependency&gt; spring-context 会自动将 spring-core、spring-beans、spring-aop、spring-expression 这几个基础 jar 包带进来。 定义一个接口 （类比的话，就是主物上面的一个接口）123public interface MessageService { String getMessage();} 定义接口实现类（类比的话，就是零件自身），并且使用注解注册到 Spring 商城 1234567@Component(\"messageService\")public class MessageServiceImpl implements MessageService { public String getMessage() { return \"hello world\"; }} 使用： （类比的话，就是从商城买东西） （这里没有使用依赖注入（自动装配），下面会介绍）12345678910// Main.java@ComponentScan // 非常重要，会扫描包下所有注解public class Main { public static void main(String[] args) { ApplicationContext context = new AnnotationConfigApplicationContext(Main.class); MessageService messageService = (MessageService) context.getBean(\"messageService\"); System.out.println(messageService.getMessage()); // 输出 Hello, World }} SpringIOC 登记方式Spring中管理的对象都叫 Bean，就像商城里面的一种商品。Spring 管理的对象默认是单例的，也就是一种商品只有一件，不过可以重复购买（注入）。下面，我们说一下如何上架这些商品。 普通类的对象登记 @Component 通用的登记方式，以下的注解都包含这个注解的功能，并且可能有额外的含义 @Service 通常用于服务层 @Controller 通常用于控制层 @Repository 通常用于数据库仓库层 后面加(“”) 定义 bean 的名字，也可以不定义自动由 Spring 生成。 例子：1234567@Component(\"messageService\")public class MessageServiceImpl implements MessageService { public String getMessage() { return \"hello world\"; }} 工厂创建的对象登记我们有时候想通过一个工厂的方式，根据传入不同对象，生成不同的对象，并登记到 Spring，我们要这么做1234567891011121314@Configurationpublic class DataConfig{ @Bean(\"aSource\") // 配置文件来源，通常用 properties 文件定义 public DataSource source(){ DataSource source = new RedisProperties(); source.setHost(\"localhost\"); source.setPassword(\"123\"); return source; } @Bean(name = \"redisTemplate\") public RedisTemplate redisTemplate(@Qualifier(\"aSource\") DataSource source) { return super.stringRedisTemplate(source); }} 我们现在就注册到了一个 redisTemplate 的 Bean，是通过我们的配置文件生产的。其中有这些注解 @Configuration 说明这是个配置类 @Bean 说明这个函数是用来创建 Bean 的 @Qualifier 说明我们引入哪一个 Bean 作为 传入参数。 我们可以写多组这样的函数，就会创造出不同的 Bean 另外还有可能用到的是 @Lazy ，可以让 bean 在用的时候再加载。 SpringIOC 注入方式当然，除了上面的 getBean 外，Spring还给我们封装了许多方法方便我们买东西：其中，@Autowired 注解 最常用，意思是按类型装配，如果这个类型的零件只有一个，那么就默认选这一个。如果是有多个，那么还需要我们指定具体是哪一个。 setter12345678@Componentpublic class Customer { private Person person; @Autowired public void setPerson (Person person) { this.person=person; }} filed123456@Componentpublic class Customer { @Autowired private Person person; private int type;} 构造函数12345678@Componentpublic class Customer { private Person person; @Autowired // 甚至可以直接不写 public Customer (Person person) { this.person=person; }} 如果一个类型对应多个 Bean，使用 @Qualifier 指定123456789101112131415@Componentpublic class BeanB1 implements BeanInterface { //}@Componentpublic class BeanB2 implements BeanInterface { //}@Componentpublic class BeanA { @Autowired @Qualifier(\"beanB2\") private BeanInterface dependency; ...} Spring IOC 生命周期与扩展点Spring IOC生命周期： 初始化 BeanFactory 创建 BeanFactory 读取 BeanDefinition 通过BeanDefinition，初始化 Bean 供外部调用 BeanFactory销毁 我们可以在 Spring IOC 的生命周期中置入各种我们自定义的逻辑。 单独类实现接口，一般是应用于全局的 Bean 继承 Aware 类，一般是用于该 Bean 获取环境变量 Bean 实现 接口，一般是用于该 Bean Bean 上 注解，一般是用于该 Bean 初始化 BeanFactory 之后实现 BeanFactoryPostProcessor 在BeanFactory初始化之后（已经读取了配置但还没初始化Bean），做一些操作，可以读取并修改BeanDefinition1234567@Componentpublic class LifeCycleControl implements BeanFactoryPostProcessor { @Override public void postProcessBeanFactory(ConfigurableListableBeanFactory beanFactory) throws BeansException { //.. doSomeThing }} 初始化 Bean 时顺序如下： 开始几步分别是：实例化、构造函数、设置属性函数，并且，在这里，其实Spring__早就已经把所有属性都注入好了__，下面的过程都是 Spring 预留给用户扩展的。 BeanNameAware__抽象类__ 可以 获取到 BeanName，其他几个 Aware 类似 1234567@Componentpublic class TestB extends BeanNameAware { @Override public void setBeanName(String name) { // 会告诉 TestB 他的 BeanName 是什么 }} BeanPostProcessor__接口 对每一个 Bean__ 初始化前后进行置入，有多少个 Bean 就会执行多少次 postProcessBeforeInitialization(Object bean, String beanName) postProcessAfterInitialization(Object bean, String beanName) @PostConstruct 注解（在Bean上），用户自定义的该Bean的初始化操作 InitializingBean接口的afterPropertiesSet()方法会被调用 init-method 用注解的话，这个一般不用了，一定要用的话，可以用 @Bean(initMethod = “initMethodName”)，在配置中心配置，不能在 Bean 上配置。 Spring IOC 构成BeanBean 是 Spring 里面最基本的单位，如果把 Spring 管理的对象看成一群人，那么 Bean 就是每一个人。在用户看来，bean 就是一个实际的对象，比如1MessageService messageService = context.getBean(MessageService.class); 在Spring内部，Bean的本质是一个 BeanName -&gt; BeanDefinition 的键值对 ，即用于搜索的名字，和他的实际定义内容。比如：1&lt;bean id=\"messageService\" class=\"ma.luan.example.MessageServiceImpl\"/&gt; 就定义了一个 Bean，Name 是 messageService ，BeanDefinition 的内容之一是 ma.luan.example.MessageServiceImpl ApplicationContext：Spring IOC 的门面，供用户调用，起到统筹全局的作用。背后它从源(Resource)读取配置 ，为每个 bean 生成配置对象(BeanDefinition) 到工厂(BeanFactory)的注册中心(Registry) ，控制工厂管理 Bean (Autowire)，代理工厂的 getBean 操作。我们可以使用多种输入方式 Context。 BeanFactorySpring 的核心，他管理着一个注册中心 Registry，并且负责管理 Bean（加载类，实例化，注入属性等），并且提供 getBean 等操作 BeanFactory: 可以获取一个 Bean 的能力的接口，有getBean方法 ListableBeanFactory，有一次获取多个 Bean 能力的接口，有getBeans方法 HierarchicalBeanFactory，有继承能力的工厂接口，有一个 getParentBeanFactory 方法，可以获取父工厂，先不用管 AutowireCapableBeanFactory 可以自动装配的工厂接口，继承它让我们的工厂可以对 Bean 自动创建，属性进行自动插入的能力。autowireBean、createBean、initializeBean、applyBeanPostProcessorsBeforeInitialization 等等，是工厂最核心的能力 DefaultListableBeanFactory，继承了所有接口，是我们最常使用的标准工厂。他继承并实现了所有的能力 getBean getBeans getParentBeanFactory AutowireCapable Config （修改设置） ApplicationContext虽然也继承了 BeanFactory，但是实际上是复用了他的 getBean() 等接口，实际逻辑代码并没有什么继承关系。 BeanRegistry注册中心，维护着多个 Map，用于登记 Bean 的信息，包括 BeanDefinition 的 Map，还有 存放单例的 singletonObjects 的 Map 等等。 BeanDefinitionBeanDefinition存放我们在配置文件中对某个 Bean 的所有注册信息，和存放该对象的实际单例对象。比如，我们在 xml 文件中配置1&lt;bean id=\"messageService\" class=\"ma.luan.example.MessageServiceImpl\"/&gt; 那么， BeanRegistry 中 会有messageService -&gt; BeanDefinitionBeanDefinition里面有关于这个 Bean 的所有配置 ResourceLoader负责从多个配置源（Resource）读取配置文件，源包括 XML、注解等等，XML有可能来自本地或者网络。 DefinitionReader从 ResourceLoader 加载到配置资源后，把配置转成（read） Definition 的形式 启动过程分析简单起见，我们可能还是要用回 XML 配置启动的方法（ClassPathXmlApplicationContext）来分析 （真香），不过其实内部大同小异。 123456public static void main(String[] args) { ApplicationContext context = new ClassPathXmlApplicationContext(\"classpath:application.xml\"); MessageService messageService = context.getBean(MessageService.class); System.out.println(messageService.getMessage()); // 输出 hello world} ClassPathXmlApplicationContext 构造方法123456789public ClassPathXmlApplicationContext(String[] configLocations, boolean refresh, ApplicationContext parent) throws BeansException { super(parent); setConfigLocations(configLocations); // 保存XML路径 if (refresh) { refresh(); // 第一次执行会到这里，初始化 }} 核心启动器：refresh 方法refresh方法是启动的核心方法，执行了启动的所有操作，后面还会提到余下的部分 123456789101112public void refresh() throws BeansException, IllegalStateException { synchronized (this.startupShutdownMonitor) { // 准备工作，记录下容器的启动时间、标记“已启动”状态、处理配置文件中的占位符 prepareRefresh(); // 创建工厂，读取 XML，把 BeanName -&gt; BeanDefinition 在 BeanFactory 的 Registry 里 注册 ConfigurableListableBeanFactory beanFactory = obtainFreshBeanFactory(); // .... }} 创建工厂并在 Context 中保存引用obtainFreshBeanFactory 方法这个方法干了下面几件事 创建了 beanFactory （DefaultListableBeanFactory），并且把 beanFactory 赋值给 Context 保存 读取 Context 的配置，设置该工厂 是否允许 Bean 覆盖、是否允许循环引用 等 Context 读取加载 BeanDefinition，把 BeanDefinition 注册到 BeanFactory 的 Map 中 配置 DefinitionReader，读取 Resource 从XML读取配置树，转换成 Definition，触发监听事件 创建好之后的 beanFactory 的一部分的截图 创建工厂后的维护操作主要是在 BeanFactory 里面注册实现了各种接口的Bean，Factory会为每一个特殊的接口类型维护一个列表，以后到达特定的位置，就会遍历这个列表。比如 实现了 BeanPostProcessors 的接口的 Bean 有 A，B，C，那么到时候初始化 Bean 之前，就会遍历调用A，B，C的 postProcessBeforeInitialization方法，初始化 Bean 之后，就会调用 A，B，C 的postProcessAfterInitialization 方法，具体什么时候调用什么方法，请查看后面写的 Spring Bean 生命周期 1234567891011121314151617181920212223242526272829303132333435@Overridepublic void refresh() throws BeansException, IllegalStateException {synchronized (this.startupShutdownMonitor) { prepareRefresh(); ConfigurableListableBeanFactory beanFactory = obtainFreshBeanFactory(); // 主要是设置 BeanFactory 的 ClassLoader prepareBeanFactory(beanFactory); try { // 注册实现了 BeanFactory 的 Bean postProcessBeanFactory(beanFactory); // 调用上面注册的 Bean 的相关方法 （用于 BeanFactory 读取 Definition 之后，初始化之前） invokeBeanFactoryPostProcessors(beanFactory); // 这个比较会用到，检测 注册好的 Bean 里面，实现了 BeanPostProcessors 接口的 Bean // 等下初始化 Bean 的前后，会调用这些所有 Bean 的 相关方法 registerBeanPostProcessors(beanFactory); // 国际化的，用不到 initMessageSource(); // 注册ApplicationEvent接口的Bean，初始化事件广播器 initApplicationEventMulticaster(); // 给子类的钩子，会再注册一些内置 Bean onRefresh(); // 注册实现了 ApplicationListener 接口的 Bean registerListeners(); // 初始化所有的 singleton beans （lazy-init 的除外）：下面讲 finishBeanFactoryInitialization(beanFactory); // ... } //... } 初始化 BeanSpring 默认 初始化的 Bean对象 都是单例的，采用的是单例注册表的方法。我们重点关注单例如何实现，怎么解决循环引用 首先，初始化入口在 finishBeanFactoryInitialization(beanFactory)，就是在 refresh() 方法的尾部。这个方法会进行马上初始化的 bean 进行马上初始化。 因为要兼容 延迟初始化（getBean时候加载） 和 马上初始化，所以最合适的方式就是把加载的逻辑写在 getBean 里边，需要马上加载的时候，提前调用 getBean 即可。 finishBeanFactoryInitialization核心方法是 preInstantiateSinletons()：对符合条件的所有 beandefinition 里面 的 bean 执行了初始化操作：12345678910111213141516171819202122public void preInstantiateSingletons() throws BeansException { // this.beanDefinitionNames 保存了所有的 beanNames List&lt;String&gt; beanNames = new ArrayList&lt;String&gt;(this.beanDefinitionNames); // 触发所有的非懒加载的 singleton beans 的初始化操作 for (String beanName : beanNames) { // 非抽象、非懒加载的 singletons。如果配置了 'abstract = true'，那是不需要初始化的 if (!bd.isAbstract() &amp;&amp; bd.isSingleton() &amp;&amp; !bd.isLazyInit()) { if (isFactoryBean(beanName)) { // FactoryBean 的话，在 beanName 前面加上 ‘&amp;’ 符号。再调用 getBean final FactoryBean&lt;?&gt; factory = (FactoryBean&lt;?&gt;) getBean(FACTORY_BEAN_PREFIX + beanName); } else { // 对于普通的 Bean，只要调用 getBean(beanName) 这个方法就可以进行初始化了 getBean(beanName); } } } } getBean我去掉了部分无关紧要的代码，如果有兴趣可以去看原文件 AbstractBeanFactory1234567891011121314151617181920212223242526272829303132333435@Overridepublic Object getBean(String name) throws BeansException { return doGetBean(name, null, null, false);}@SuppressWarnings(\"unchecked\")protected &lt;T&gt; T doGetBean( final String name, final Class&lt;T&gt; requiredType, final Object[] args, boolean typeCheckOnly) throws BeansException { // 获取 BeanName final String beanName = transformedBeanName(name); // 这个是返回值 Object bean; // 检查单例是否已经初始化，单例全部注册在 regisrty 的 singletonObjects，多例不会在这里注册 Object sharedInstance = getSingleton(beanName); // 如果注册表中没有这个单例，会返回 null，后面还会讲到这个方法 // 开始创建 bean if (sharedInstance != null) { bean = getObjectForBeanInstance(sharedInstance, name, beanName, null); // 默认非 BeanFactor 时，等同于 bean = sharedInstance } else { // 如果上面为 null,则说明单例未初始化，或者是多例 final RootBeanDefinition mbd = getMergedLocalBeanDefinition(beanName); // 这里，实际执行了：this.beanDefinitionMap.get(beanName) // 就是把 BeanDefinition 拿出来了 // 这里有一百多行代码，除了插入各种钩子和特殊情况，其实我们只执行了一行代码 bean = createBean(beanName, mbd, args) ｝ return (T) bean; } 所以，getBean 就是 配套钩子 + 执行 createBean 方法创建好的对象会放在 单例注册表 singletonObjects 中，下次再取的时候就从表里取，而不重新创建，从而实现单例模式。 createBean方法如果单例还未创建，会在此创建 BeancreateBean 方法 主要做了些前置的工作，包括给 AOP 预留的拦截器 （AOP时，返回 Proxy 对象而不是真正的对象）然后委托给 doCreateBean 方法，主要做了下面这些事： 实例化对象 装配属性 执行 InitializingBean 接口，BeanPostProcessor 接口钩子， init 方法钩子 （生命周期钩子） 我们主要关心一下怎么解决循环引用的问题：123456789&lt;bean id=\"circleA\" class=\"entity.CircleA\" &gt; &lt;property name=\"circleB\" ref=\"circleB\"/&gt;&lt;/bean&gt;&lt;bean id=\"circleB\" class=\"entity.CircleB\" &gt; &lt;property name=\"circleC\" ref=\"circleC\"/&gt;&lt;/bean&gt;&lt;bean id=\"circleC\" class=\"entity.CircleC\" &gt; &lt;property name=\"circleA\" ref=\"circleA\"/&gt;&lt;/bean&gt; 这样就构成了一个循环依赖，而我们默认是单例的，那如何一次性创建三个对象呢？首先，在实例化对象的时候，先在 singletonFactories 注册一个工厂1234567addSingletonFactory(beanName, new ObjectFactory&lt;Object&gt;() { @Override public Object getObject() throws BeansException { return getEarlyBeanReference(beanName, mbd, bean); }});// this.singletonFactories.put(beanName, singletonFactory); circleA 属性注入时，到了 circleB ，会 getBean(circleB) ，然后又会 getBean(circleC)getBean(circleC) 时，又看到了A ，会调用回 getBean(circleA)，在getBean的时候，会调用getSingleton，他会先从工厂取，这个时候A已经在工厂列表了，然后用getObject，就可以拿到A的引用。 123456789101112131415161718192021protected Object getSingleton(String beanName, boolean allowEarlyReference) { Object singletonObject = this.singletonObjects.get(beanName); // getBean 默认走这里，从单例注册表拿已经创建好的单例，但是现在A还没创建好 if (singletonObject == null &amp;&amp; isSingletonCurrentlyInCreation(beanName)) { // 单例注册表里面没有，对象正在初始化，符合循环引用的条件 synchronized (this.singletonObjects) { singletonObject = this.earlySingletonObjects.get(beanName); if (singletonObject == null &amp;&amp; allowEarlyReference) { ObjectFactory&lt;?&gt; singletonFactory = this.singletonFactories.get(beanName); if (singletonFactory != null) { singletonObject = singletonFactory.getObject(); // getObject，就是把A的引用拉过来了，A其实还没建好，不过他的引用已经有了 this.earlySingletonObjects.put(beanName, singletonObject); this.singletonFactories.remove(beanName); } } } } // 返回A的引用给C return (singletonObject != NULL_OBJECT ? singletonObject : null);} 这样就可以解决循环引用的问题 拾遗Spring中的监听器用法123456789101112131415161718192021222324252627282930313233// 自定义事件public class MyEvent extends ApplicationEvent { public MyEvent(Object source) { super(source); }}// 自定义 Bean 实现 ApplicationContextAware 接口@Componentpublic class HelloBean implements ApplicationContextAware { private ApplicationContext applicationContext; private String name; public void setApplicationContext(ApplicationContext context) { this.applicationContext = context; } // 当调用 setName 时, 触发事件 public void setName(String name) { this.name = name; applicationContext.publishEvent(new MyEvent(this)); // 这行代码执行完会立即被监听到 } public String getName() { return name; }}// 自定义监听器, 监听上面的事件@Componentpublic class MyApplicationListener implements ApplicationListener { @Override public void onApplicationEvent(ApplicationEvent event) { if (event instanceof MyEvent) { System.out.println(((HelloBean)event.getSource()).getName()); } }} Spring IOC中的主要设计模式 单例模式 观察者模式 （Listener） 参考资料Spring IOC 容器源码分析Tiny-spring: A tiny IoC container refer to Spring. Spring4参考手册中文版Spring Framework Reference DocumentationSpring的扩展点Spring Bean Life Cycle Tutorial","link":"/2018/07/26/yuque/spring-ioc/"}],"tags":[{"name":"Hexo","slug":"Hexo","link":"/tags/Hexo/"},{"name":"语雀","slug":"语雀","link":"/tags/语雀/"},{"name":"Java 核心","slug":"Java-核心","link":"/tags/Java-核心/"},{"name":"小小商城","slug":"小小商城","link":"/tags/小小商城/"},{"name":"SSM","slug":"SSM","link":"/tags/SSM/"},{"name":"Spring Boot","slug":"Spring-Boot","link":"/tags/Spring-Boot/"},{"name":"Servlet","slug":"Servlet","link":"/tags/Servlet/"},{"name":"SSH","slug":"SSH","link":"/tags/SSH/"},{"name":"网络","slug":"网络","link":"/tags/网络/"},{"name":"Netty","slug":"Netty","link":"/tags/Netty/"},{"name":"Spring","slug":"Spring","link":"/tags/Spring/"},{"name":"Spring MVC","slug":"Spring-MVC","link":"/tags/Spring-MVC/"}],"categories":[{"name":"日志","slug":"日志","link":"/categories/日志/"},{"name":"技术笔记","slug":"技术笔记","link":"/categories/技术笔记/"},{"name":"项目","slug":"项目","link":"/categories/项目/"},{"name":"技术实战","slug":"技术实战","link":"/categories/技术实战/"},{"name":"教程","slug":"教程","link":"/categories/教程/"}]}